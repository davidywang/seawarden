#tif output fodler
tif_folder <- '/Users/Zack/0_sst/ghrsst_2019_tif_u/'
#area of interest for clipping tif
area <- st_read('/Users/Zack/0_seawarden/0_search_areas/3_aoi/GRC_aoi.shp')
#list all files in folder
folder_list <- list.files(nc_folder)
#for loop
for (i in folder_list){
filename = paste0(nc_folder, i)
netcdf_converter(filename)}
# function
netcdf_converter <- function(file){
nc_data <- nc_open(file)
# get the lat, lon, and time coordinates
lon <- ncvar_get(nc_data, "lon")
lat <- ncvar_get(nc_data, "lat", verbose = F)
t <- ncvar_get(nc_data, "time")
SST.array <- ncvar_get(nc_data, "analysis_error") # store the data in a 3-dimensional array
fillvalue <- ncatt_get(nc_data, "analysis_error", "_FillValue") # get the fill value
nc_close(nc_data)
SST.array[SST.array == fillvalue$value] <- NA
SST.slice <- SST.array[, ] # get the first time slice
# save this time slice as a raster
r <- raster(t(SST.slice), xmn=min(lon), xmx=max(lon), ymn=min(lat), ymx=max(lat), crs=CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs+ towgs84=0,0,0"))
r <- flip(r, direction='y')
r <- crop_tool(r, area)
name <- substr(file, 10, 50) #38, 45) #20190109
filepath <- paste(tif_folder, "L4_GHRSST-", name , ".tif", sep="")
writeRaster(r, filepath, "GTiff", overwrite=TRUE)}
#nc input folder
nc_folder <- '/Users/Zack/0_sst/ghrsst_2019/' #355 days
#tif output fodler
tif_folder <- '/Users/Zack/0_sst/ghrsst_2019_tif_u/'
#area of interest for clipping tif
area <- st_read('/Users/Zack/0_seawarden/0_search_areas/3_aoi/GRC_aoi.shp')
#list all files in folder
folder_list <- list.files(nc_folder)
#for loop
for (i in folder_list){
filename = paste0(nc_folder, i)
netcdf_converter(filename)}
# function
netcdf_converter <- function(file){
nc_data <- nc_open(file)
# get the lat, lon, and time coordinates
lon <- ncvar_get(nc_data, "lon")
lat <- ncvar_get(nc_data, "lat", verbose = F)
t <- ncvar_get(nc_data, "time")
SST.array <- ncvar_get(nc_data, "analysis_error") # store the data in a 3-dimensional array
fillvalue <- ncatt_get(nc_data, "analysis_error", "_FillValue") # get the fill value
nc_close(nc_data)
SST.array[SST.array == fillvalue$value] <- NA
SST.slice <- SST.array[, ] # get the first time slice
# save this time slice as a raster
r <- raster(t(SST.slice), xmn=min(lon), xmx=max(lon), ymn=min(lat), ymx=max(lat), crs=CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs+ towgs84=0,0,0"))
r <- flip(r, direction='y')
r <- crop_tool(r, area)
name <- substr(file, 30, 50) #38, 45) #20190109
filepath <- paste(tif_folder, "L4_GHRSST-", name , ".tif", sep="")
writeRaster(r, filepath, "GTiff", overwrite=TRUE)}
#function test
file <- '/Users/Zack/0_thesis_sst/ghrsst_2018/20180101000000-GOS-L4_GHRSST-SSTfnd-OISST_UHR_NRT-MED-v02.0-fv01.0.nc'
netcdf_converter(file)
netcdf_converter(file)
# function
netcdf_converter <- function(file){
nc_data <- nc_open(file)
# get the lat, lon, and time coordinates
lon <- ncvar_get(nc_data, "lon")
lat <- ncvar_get(nc_data, "lat", verbose = F)
t <- ncvar_get(nc_data, "time")
SST.array <- ncvar_get(nc_data, "analysis_error") # store the data in a 3-dimensional array
fillvalue <- ncatt_get(nc_data, "analysis_error", "_FillValue") # get the fill value
nc_close(nc_data)
SST.array[SST.array == fillvalue$value] <- NA
SST.slice <- SST.array[, ] # get the first time slice
# save this time slice as a raster
r <- raster(t(SST.slice), xmn=min(lon), xmx=max(lon), ymn=min(lat), ymx=max(lat), crs=CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs+ towgs84=0,0,0"))
r <- flip(r, direction='y')
r <- crop_tool(r, area)
name <- substr(file, 38, 50) #38, 45) #20190109
filepath <- paste(tif_folder, "L4_GHRSST-", name , ".tif", sep="")
writeRaster(r, filepath, "GTiff", overwrite=TRUE)}
#function test
file <- '/Users/Zack/0_thesis_sst/ghrsst_2018/20180101000000-GOS-L4_GHRSST-SSTfnd-OISST_UHR_NRT-MED-v02.0-fv01.0.nc'
netcdf_converter(file)
# function
netcdf_converter <- function(file){
nc_data <- nc_open(file)
# get the lat, lon, and time coordinates
lon <- ncvar_get(nc_data, "lon")
lat <- ncvar_get(nc_data, "lat", verbose = F)
t <- ncvar_get(nc_data, "time")
SST.array <- ncvar_get(nc_data, "analysis_error") # store the data in a 3-dimensional array
fillvalue <- ncatt_get(nc_data, "analysis_error", "_FillValue") # get the fill value
nc_close(nc_data)
SST.array[SST.array == fillvalue$value] <- NA
SST.slice <- SST.array[, ] # get the first time slice
# save this time slice as a raster
r <- raster(t(SST.slice), xmn=min(lon), xmx=max(lon), ymn=min(lat), ymx=max(lat), crs=CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs+ towgs84=0,0,0"))
r <- flip(r, direction='y')
r <- crop_tool(r, area)
name <- substr(file, 38, 45) #38, 45) #20190109
filepath <- paste(tif_folder, "L4_GHRSST-", name , ".tif", sep="")
writeRaster(r, filepath, "GTiff", overwrite=TRUE)}
#function test
file <- '/Users/Zack/0_thesis_sst/ghrsst_2018/20180101000000-GOS-L4_GHRSST-SSTfnd-OISST_UHR_NRT-MED-v02.0-fv01.0.nc'
netcdf_converter(file)
# function
netcdf_converter <- function(file){
nc_data <- nc_open(file)
# get the lat, lon, and time coordinates
lon <- ncvar_get(nc_data, "lon")
lat <- ncvar_get(nc_data, "lat", verbose = F)
t <- ncvar_get(nc_data, "time")
SST.array <- ncvar_get(nc_data, "analysis_error") # store the data in a 3-dimensional array
fillvalue <- ncatt_get(nc_data, "analysis_error", "_FillValue") # get the fill value
nc_close(nc_data)
SST.array[SST.array == fillvalue$value] <- NA
SST.slice <- SST.array[, ] # get the first time slice
# save this time slice as a raster
r <- raster(t(SST.slice), xmn=min(lon), xmx=max(lon), ymn=min(lat), ymx=max(lat), crs=CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs+ towgs84=0,0,0"))
r <- flip(r, direction='y')
r <- crop_tool(r, area)
name <- substr(file, 38, 45) #38, 45) #20190109
filepath <- paste(tif_folder, "L4_GHRSST-", name , ".tif", sep="")
writeRaster(r, filepath, "GTiff", overwrite=TRUE)}
#function test
file <- '/Users/Zack/0_sst/ghrsst_2018/20180101000000-GOS-L4_GHRSST-SSTfnd-OISST_UHR_NRT-MED-v02.0-fv01.0.nc'
netcdf_converter(file)
name
# function
netcdf_converter <- function(file){
nc_data <- nc_open(file)
# get the lat, lon, and time coordinates
lon <- ncvar_get(nc_data, "lon")
lat <- ncvar_get(nc_data, "lat", verbose = F)
t <- ncvar_get(nc_data, "time")
SST.array <- ncvar_get(nc_data, "analysis_error") # store the data in a 3-dimensional array
fillvalue <- ncatt_get(nc_data, "analysis_error", "_FillValue") # get the fill value
nc_close(nc_data)
SST.array[SST.array == fillvalue$value] <- NA
SST.slice <- SST.array[, ] # get the first time slice
# save this time slice as a raster
r <- raster(t(SST.slice), xmn=min(lon), xmx=max(lon), ymn=min(lat), ymx=max(lat), crs=CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs+ towgs84=0,0,0"))
r <- flip(r, direction='y')
r <- crop_tool(r, area)
name <- substr(file, 30, 45) #38, 45) #20190109
filepath <- paste(tif_folder, "L4_GHRSST-", name , ".tif", sep="")
writeRaster(r, filepath, "GTiff", overwrite=TRUE)}
#function test
file <- '/Users/Zack/0_sst/ghrsst_2018/20180101000000-GOS-L4_GHRSST-SSTfnd-OISST_UHR_NRT-MED-v02.0-fv01.0.nc'
netcdf_converter(file)
# function
netcdf_converter <- function(file){
nc_data <- nc_open(file)
# get the lat, lon, and time coordinates
lon <- ncvar_get(nc_data, "lon")
lat <- ncvar_get(nc_data, "lat", verbose = F)
t <- ncvar_get(nc_data, "time")
SST.array <- ncvar_get(nc_data, "analysis_error") # store the data in a 3-dimensional array
fillvalue <- ncatt_get(nc_data, "analysis_error", "_FillValue") # get the fill value
nc_close(nc_data)
SST.array[SST.array == fillvalue$value] <- NA
SST.slice <- SST.array[, ] # get the first time slice
# save this time slice as a raster
r <- raster(t(SST.slice), xmn=min(lon), xmx=max(lon), ymn=min(lat), ymx=max(lat), crs=CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs+ towgs84=0,0,0"))
r <- flip(r, direction='y')
r <- crop_tool(r, area)
name <- substr(file, 31, 45) #38, 45) #20190109
filepath <- paste(tif_folder, "L4_GHRSST-", name , ".tif", sep="")
writeRaster(r, filepath, "GTiff", overwrite=TRUE)}
#function test
file <- '/Users/Zack/0_sst/ghrsst_2018/20180101000000-GOS-L4_GHRSST-SSTfnd-OISST_UHR_NRT-MED-v02.0-fv01.0.nc'
netcdf_converter(file)
# function
netcdf_converter <- function(file){
nc_data <- nc_open(file)
# get the lat, lon, and time coordinates
lon <- ncvar_get(nc_data, "lon")
lat <- ncvar_get(nc_data, "lat", verbose = F)
t <- ncvar_get(nc_data, "time")
SST.array <- ncvar_get(nc_data, "analysis_error") # store the data in a 3-dimensional array
fillvalue <- ncatt_get(nc_data, "analysis_error", "_FillValue") # get the fill value
nc_close(nc_data)
SST.array[SST.array == fillvalue$value] <- NA
SST.slice <- SST.array[, ] # get the first time slice
# save this time slice as a raster
r <- raster(t(SST.slice), xmn=min(lon), xmx=max(lon), ymn=min(lat), ymx=max(lat), crs=CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs+ towgs84=0,0,0"))
r <- flip(r, direction='y')
r <- crop_tool(r, area)
name <- substr(file, 31, 38) #38, 45) #20190109
filepath <- paste(tif_folder, "L4_GHRSST-", name , ".tif", sep="")
writeRaster(r, filepath, "GTiff", overwrite=TRUE)}
#function test
file <- '/Users/Zack/0_sst/ghrsst_2018/20180101000000-GOS-L4_GHRSST-SSTfnd-OISST_UHR_NRT-MED-v02.0-fv01.0.nc'
netcdf_converter(file)
# function
netcdf_converter <- function(file){
nc_data <- nc_open(file)
# get the lat, lon, and time coordinates
lon <- ncvar_get(nc_data, "lon")
lat <- ncvar_get(nc_data, "lat", verbose = F)
t <- ncvar_get(nc_data, "time")
SST.array <- ncvar_get(nc_data, "analysis_error") # store the data in a 3-dimensional array
fillvalue <- ncatt_get(nc_data, "analysis_error", "_FillValue") # get the fill value
nc_close(nc_data)
SST.array[SST.array == fillvalue$value] <- NA
SST.slice <- SST.array[, ] # get the first time slice
# save this time slice as a raster
r <- raster(t(SST.slice), xmn=min(lon), xmx=max(lon), ymn=min(lat), ymx=max(lat), crs=CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs+ towgs84=0,0,0"))
r <- flip(r, direction='y')
r <- crop_tool(r, area)
name <- substr(file, 31, 38) #38, 45)
filepath <- paste(tif_folder, "L4_GHRSST-", name , ".tif", sep="")
writeRaster(r, filepath, "GTiff", overwrite=TRUE)}
#function test
file <- '/Users/Zack/0_sst/ghrsst_2018/20180101000000-GOS-L4_GHRSST-SSTfnd-OISST_UHR_NRT-MED-v02.0-fv01.0.nc'
netcdf_converter(file)
#nc input folder
nc_folder <- '/Users/Zack/0_sst/ghrsst_2019/' #355 days
#tif output fodler
tif_folder <- '/Users/Zack/0_sst/ghrsst_2019_tif_u/'
#area of interest for clipping tif
area <- st_read('/Users/Zack/0_seawarden/0_search_areas/3_aoi/GRC_aoi.shp')
#list all files in folder
folder_list <- list.files(nc_folder)
#for loop
for (i in folder_list){
filename = paste0(nc_folder, i)
netcdf_converter(filename)}
library(dplyr)
library(raster)
library(sf)
#parallel processing - http://pablobarbera.com/ECPR-SC105/code/02-parallel-computing.html
library(foreach)
library(doParallel)
library(ggplot2)
library(scales)
library(dplyr)
library(raster)
library(sf)
#parallel processing - http://pablobarbera.com/ECPR-SC105/code/02-parallel-computing.html
library(foreach)
library(doParallel)
library(ggplot2)
library(scales)
#load shapefile of farm sites
targets <- '/Users/Zack/0_seawarden/greece/1_sites/farm_500m_update_sst.shp'
targets <- st_read(targets)
#function to crop raster to area of interest, converts raster to point
crop_tool <- function(image_file, target){
raster_crop <- crop(raster(image_file), target) #opens raster file, clips raster to target (target is opened in a prior step)
pts <- rasterToPoints(raster_crop) #raster clip is convereted to a point
pts_df <- as.data.frame(pts) #points converted to a df
mean(pts_df[,3])} #mean calculated to result in just one measurement
#extract sst from all rasters and add sst value to csv
sst_tool <- function(tif_folder, target, csv_output){
sst_list <- list.files(tif_folder, pattern = '.tif')
daily_sst = list() #365 tif files per year/folder
date = list()
library(raster) #added for parallel processing
#365 for 2018, sst_list for 2019
#for (i in 1:365){
for (i in 1:(length(sst_list))){
file <- paste0(tif_folder, sst_list[i])
sst <- crop_tool(file, target)
daily_sst[[i]] <- sst
day <- substr(sst_list[i], 17, 18)
month <- substr(sst_list[i], 15, 16)
year <- substr(sst_list[i], 11, 14)
date[[i]] <- paste0(day, "/", month, "/", year)}
daily_sst = do.call(rbind, daily_sst)
date = data.frame(do.call(rbind, date))
#rename columns
colnames(daily_sst) <- c("c")
colnames(date) <- c("date")
#convert kelvin to celcius
daily_sst <- daily_sst - 273.15
#add date
daily_sst <- cbind(date, daily_sst)
#create output filename and export as csv
output <- paste0(csv_output, target$farm_id, '_sst.csv')
write.table(daily_sst, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
#process SST for all farm sites - one year at a time
#load sst data
#tif_folder <- '/Users/Zack/0_thesis_sst/ghrsst_2018_tif/'
#tif_folder <- '/Users/Zack/0_thesis_sst/ghrsst_2019_tif/'
tif_folder <- '/Users/Zack/0_thesis_sst/ghrsst_2019_tif_u/'
#output folder
#csv_output <- '/Users/Zack/0_thesis_sst/ghrsst_2018_csv/'
#csv_output <- '/Users/Zack/0_thesis_sst/ghrsst_2019_csv/'
csv_output <- '/Users/Zack/0_thesis_sst/ghrsst_2019_csv_u/'
#single use
#sst_tool(tif_folder, targets[1,], csv_output)
#loop to extract SST for all farm sites
# for (i in 1:10)
# for (i in 1:nrow(as.data.frame(targets)))
# {sst_tool(tif_folder, targets[i,], csv_output)}
#select numbrer of cores
myCluster <- makeCluster(4, type = "PSOCK")
#activate clusters
registerDoParallel(myCluster)
#parallel process
foreach(i = 0:nrow(as.data.frame(targets))) %dopar% sst_tool(tif_folder, targets[i,], csv_output)
#process SST for all farm sites - one year at a time
#load sst data
#tif_folder <- '/Users/Zack/0_thesis_sst/ghrsst_2018_tif/'
#tif_folder <- '/Users/Zack/0_thesis_sst/ghrsst_2019_tif/'
tif_folder <- '/Users/Zack/0_sst/ghrsst_2019_tif_u/'
#output folder
#csv_output <- '/Users/Zack/0_thesis_sst/ghrsst_2018_csv/'
#csv_output <- '/Users/Zack/0_thesis_sst/ghrsst_2019_csv/'
csv_output <- '/Users/Zack/0_sst/ghrsst_2019_csv_u/'
#single use
#sst_tool(tif_folder, targets[1,], csv_output)
#loop to extract SST for all farm sites
# for (i in 1:10)
# for (i in 1:nrow(as.data.frame(targets)))
# {sst_tool(tif_folder, targets[i,], csv_output)}
#select numbrer of cores
myCluster <- makeCluster(4, type = "PSOCK")
#activate clusters
registerDoParallel(myCluster)
#parallel process
foreach(i = 0:nrow(as.data.frame(targets))) %dopar% sst_tool(tif_folder, targets[i,], csv_output)
stopCluster(myCluster)
sst_tool(tif_folder, targets[1,], csv_output)
sst_tool(tif_folder, targets[2,], csv_output)
sst_tool(tif_folder, targets[3,], csv_output)
#nc input folder
nc_folder <- '/Users/Zack/0_sst/ghrsst_2018/' #355 days
#tif output fodler
tif_folder <- '/Users/Zack/0_sst/ghrsst_2018_tif_u/'
#area of interest for clipping tif
area <- st_read('/Users/Zack/0_seawarden/0_search_areas/3_aoi/GRC_aoi.shp')
#list all files in folder
folder_list <- list.files(nc_folder)
#for loop
for (i in folder_list){
filename = paste0(nc_folder, i)
netcdf_converter(filename)}
#https://daac.ornl.gov/resources/tutorials/NetCDF_webinar_08302017.html
library(ncdf4)
library(raster)
library(sf)
library(rgdal)
#Function to crop raster to area of interest
crop_tool <- function(raster, area){
the_crs <- crs(raster, asText = TRUE)
area_crs <- st_transform(area, crs = the_crs)
raster_crop <- crop(raster, area_crs)}
# function
netcdf_converter <- function(file){
nc_data <- nc_open(file)
# get the lat, lon, and time coordinates
lon <- ncvar_get(nc_data, "lon")
lat <- ncvar_get(nc_data, "lat", verbose = F)
t <- ncvar_get(nc_data, "time")
SST.array <- ncvar_get(nc_data, "analysis_error") # store the data in a 3-dimensional array
fillvalue <- ncatt_get(nc_data, "analysis_error", "_FillValue") # get the fill value
nc_close(nc_data)
SST.array[SST.array == fillvalue$value] <- NA
SST.slice <- SST.array[, ] # get the first time slice
# save this time slice as a raster
r <- raster(t(SST.slice), xmn=min(lon), xmx=max(lon), ymn=min(lat), ymx=max(lat), crs=CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs+ towgs84=0,0,0"))
r <- flip(r, direction='y')
r <- crop_tool(r, area)
name <- substr(file, 31, 38) #38, 45)
filepath <- paste(tif_folder, "L4_GHRSST-", name , ".tif", sep="")
writeRaster(r, filepath, "GTiff", overwrite=TRUE)}
#nc input folder
nc_folder <- '/Users/Zack/0_sst/ghrsst_2018/' #355 days
#tif output fodler
tif_folder <- '/Users/Zack/0_sst/ghrsst_2018_tif_u/'
#area of interest for clipping tif
area <- st_read('/Users/Zack/0_seawarden/0_search_areas/3_aoi/GRC_aoi.shp')
#list all files in folder
folder_list <- list.files(nc_folder)
#for loop
for (i in folder_list){
filename = paste0(nc_folder, i)
netcdf_converter(filename)}
#process SST for all farm sites - one year at a time
#load sst data
#tif_folder <- '/Users/Zack/0_thesis_sst/ghrsst_2018_tif/'
#tif_folder <- '/Users/Zack/0_thesis_sst/ghrsst_2019_tif/'
#tif_folder <- '/Users/Zack/0_sst/ghrsst_2019_tif_u/'
tif_folder <- '/Users/Zack/0_sst/ghrsst_2018_tif_u/'
#output folder
#csv_output <- '/Users/Zack/0_thesis_sst/ghrsst_2018_csv/'
#csv_output <- '/Users/Zack/0_thesis_sst/ghrsst_2019_csv/'
#csv_output <- '/Users/Zack/0_sst/ghrsst_2019_csv_u/'
csv_output <- '/Users/Zack/0_sst/ghrsst_2018_csv_u/'
#single use
#sst_tool(tif_folder, targets[1,], csv_output)
#loop to extract SST for all farm sites
# for (i in 1:10)
# for (i in 1:nrow(as.data.frame(targets)))
# {sst_tool(tif_folder, targets[i,], csv_output)}
#select numbrer of cores
myCluster <- makeCluster(4, type = "PSOCK")
#activate clusters
registerDoParallel(myCluster)
#parallel process
foreach(i = 0:nrow(as.data.frame(targets))) %dopar% sst_tool(tif_folder, targets[i,], csv_output)
library(dplyr)
library(raster)
library(sf)
#parallel processing - http://pablobarbera.com/ECPR-SC105/code/02-parallel-computing.html
library(foreach)
library(doParallel)
library(ggplot2)
library(scales)
#load shapefile of farm sites
targets <- '/Users/Zack/0_seawarden/greece/1_sites/farm_500m_update_sst.shp'
targets <- st_read(targets)
#function to crop raster to area of interest, converts raster to point
crop_tool <- function(image_file, target){
raster_crop <- crop(raster(image_file), target) #opens raster file, clips raster to target (target is opened in a prior step)
pts <- rasterToPoints(raster_crop) #raster clip is convereted to a point
pts_df <- as.data.frame(pts) #points converted to a df
mean(pts_df[,3])} #mean calculated to result in just one measurement
#extract sst from all rasters and add sst value to csv
sst_tool <- function(tif_folder, target, csv_output){
sst_list <- list.files(tif_folder, pattern = '.tif')
daily_sst = list() #365 tif files per year/folder
date = list()
library(raster) #added for parallel processing
#365 for 2018, sst_list for 2019
#for (i in 1:365){
for (i in 1:(length(sst_list))){
file <- paste0(tif_folder, sst_list[i])
sst <- crop_tool(file, target)
daily_sst[[i]] <- sst
day <- substr(sst_list[i], 17, 18)
month <- substr(sst_list[i], 15, 16)
year <- substr(sst_list[i], 11, 14)
date[[i]] <- paste0(day, "/", month, "/", year)}
daily_sst = do.call(rbind, daily_sst)
date = data.frame(do.call(rbind, date))
#rename columns
colnames(daily_sst) <- c("c")
colnames(date) <- c("date")
#convert kelvin to celcius
daily_sst <- daily_sst - 273.15
#add date
daily_sst <- cbind(date, daily_sst)
#create output filename and export as csv
output <- paste0(csv_output, target$farm_id, '_sst.csv')
write.table(daily_sst, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
#process SST for all farm sites - one year at a time
#load sst data
#tif_folder <- '/Users/Zack/0_thesis_sst/ghrsst_2018_tif/'
#tif_folder <- '/Users/Zack/0_thesis_sst/ghrsst_2019_tif/'
#tif_folder <- '/Users/Zack/0_sst/ghrsst_2019_tif_u/'
tif_folder <- '/Users/Zack/0_sst/ghrsst_2018_tif_u/'
#output folder
#csv_output <- '/Users/Zack/0_thesis_sst/ghrsst_2018_csv/'
#csv_output <- '/Users/Zack/0_thesis_sst/ghrsst_2019_csv/'
#csv_output <- '/Users/Zack/0_sst/ghrsst_2019_csv_u/'
csv_output <- '/Users/Zack/0_sst/ghrsst_2018_csv_u/'
#single use
#sst_tool(tif_folder, targets[1,], csv_output)
#loop to extract SST for all farm sites
# for (i in 1:10)
# for (i in 1:nrow(as.data.frame(targets)))
# {sst_tool(tif_folder, targets[i,], csv_output)}
#select numbrer of cores
myCluster <- makeCluster(4, type = "PSOCK")
#activate clusters
registerDoParallel(myCluster)
#parallel process
foreach(i = 0:nrow(as.data.frame(targets))) %dopar% sst_tool(tif_folder, targets[i,], csv_output)
#deactivate clusters
stopCluster(myCluster)
sst_tool(tif_folder, targets[1,], csv_output)
sst_tool(tif_folder, targets[2,], csv_output)
sst_tool(tif_folder, targets[3,], csv_output)
#function to combine SST files
combine <- function(folder_1, folder_2, folder_3){
#read csv files
csv_1 <- read.delim(paste0(folder_1, list_1[i]), sep = ',', stringsAsFactors = F, header = FALSE)
csv_2 <- read.delim(paste0(folder_2, list_1[i]), sep = ',', stringsAsFactors = F, header = FALSE)
#create output filename
output <- paste0(folder_3, paste0(list_1[i]))
#merge dataframes and export file
write.table(rbind(csv_1, csv_2), file = paste0(folder_3, paste0(list_1[i])), row.names=FALSE, col.names = FALSE, sep=",")}
#combine SST csv files
#input folders
folder_1 <- '/Users/Zack/0_thesis_sst/ghrsst_2018_csv_u/'
folder_2 <- '/Users/Zack/0_thesis_sst/ghrsst_2019_csv_u/'
#output folder
folder_3 <- '/Users/Zack/0_thesis_sst/ghrsst_csv_u/'
#list files in folders
list_1 <- list.files(folder_1, pattern = '.csv')
list_2 <- list.files(folder_2, pattern = '.csv')
#combine SST csv files
for (i in 1:(length(list_1))){
combine(folder_1, folder_2, folder_3)}
#combine SST csv files
#input folders
folder_1 <- '/Users/Zack/0_sst/ghrsst_2018_csv_u/'
folder_2 <- '/Users/Zack/0_sst/ghrsst_2019_csv_u/'
#output folder
folder_3 <- '/Users/Zack/0_sst/ghrsst_csv_u/'
#list files in folders
list_1 <- list.files(folder_1, pattern = '.csv')
list_2 <- list.files(folder_2, pattern = '.csv')
#combine SST csv files
for (i in 1:(length(list_1))){
combine(folder_1, folder_2, folder_3)}
