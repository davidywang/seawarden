{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country: TUR\n",
      "13290 total SIMRDWN predictions\n",
      "13290 total SIMRDWN predictions\n",
      "10589 total SIMRDWN predictions less than or equal to 55 meters\n",
      "10589 predictions aggregated to 3316 predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zack\\Anaconda3\\envs\\thesis\\lib\\site-packages\\geopandas\\tools\\sjoin.py:44: UserWarning: CRS of frames being joined does not match!\n",
      "  warn('CRS of frames being joined does not match!')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3316 predictions\n",
      "684 total farmsite predictions based on farmsites\n",
      "146 farm site predictions containing 4 or more net pen predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zack\\Anaconda3\\envs\\thesis\\lib\\site-packages\\ipykernel_launcher.py:150: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2663 net pen predictions within farm sites\n",
      "{'init': 'EPSG:5637'}\n",
      "2663 net pen predictions\n",
      "146 farm site predictions\n",
      "final number of predicted net pens: 2067\n",
      "final number of predicted farm sites: 104\n",
      "total coordinates (5 per detection): 520\n",
      "country: ESP\n",
      "5260 total SIMRDWN predictions\n",
      "5260 total SIMRDWN predictions\n",
      "1222 total SIMRDWN predictions less than or equal to 55 meters\n",
      "1222 predictions aggregated to 850 predictions\n",
      "850 predictions\n",
      "527 total farmsite predictions based on farmsites\n",
      "31 farm site predictions containing 4 or more net pen predictions\n",
      "227 net pen predictions within farm sites\n",
      "{'init': 'EPSG:2062'}\n",
      "227 net pen predictions\n",
      "31 farm site predictions\n",
      "final number of predicted net pens: 29\n",
      "final number of predicted farm sites: 3\n",
      "total coordinates (5 per detection): 15\n",
      "country: HRV\n",
      "7548 total SIMRDWN predictions\n",
      "7548 total SIMRDWN predictions\n",
      "4640 total SIMRDWN predictions less than or equal to 55 meters\n",
      "4640 predictions aggregated to 1250 predictions\n",
      "1250 predictions\n",
      "507 total farmsite predictions based on farmsites\n",
      "57 farm site predictions containing 4 or more net pen predictions\n",
      "678 net pen predictions within farm sites\n",
      "{'init': 'EPSG:3765'}\n",
      "678 net pen predictions\n",
      "57 farm site predictions\n",
      "final number of predicted net pens: 415\n",
      "final number of predicted farm sites: 30\n",
      "total coordinates (5 per detection): 150\n",
      "country: ITA\n",
      "6750 total SIMRDWN predictions\n",
      "6750 total SIMRDWN predictions\n",
      "2328 total SIMRDWN predictions less than or equal to 55 meters\n",
      "2328 predictions aggregated to 1207 predictions\n",
      "1207 predictions\n",
      "644 total farmsite predictions based on farmsites\n",
      "43 farm site predictions containing 4 or more net pen predictions\n",
      "486 net pen predictions within farm sites\n",
      "{'init': 'EPSG:7794'}\n",
      "486 net pen predictions\n",
      "43 farm site predictions\n",
      "final number of predicted net pens: 241\n",
      "final number of predicted farm sites: 7\n",
      "total coordinates (5 per detection): 35\n",
      "country: CYP\n",
      "1499 total SIMRDWN predictions\n",
      "1499 total SIMRDWN predictions\n",
      "850 total SIMRDWN predictions less than or equal to 55 meters\n",
      "850 predictions aggregated to 324 predictions\n",
      "324 predictions\n",
      "169 total farmsite predictions based on farmsites\n",
      "11 farm site predictions containing 4 or more net pen predictions\n",
      "136 net pen predictions within farm sites\n",
      "{'init': 'EPSG:6312'}\n",
      "136 net pen predictions\n",
      "11 farm site predictions\n",
      "final number of predicted net pens: 67\n",
      "final number of predicted farm sites: 6\n",
      "total coordinates (5 per detection): 30\n",
      "country: MLT\n",
      "198 total SIMRDWN predictions\n",
      "198 total SIMRDWN predictions\n",
      "177 total SIMRDWN predictions less than or equal to 55 meters\n",
      "177 predictions aggregated to 91 predictions\n",
      "91 predictions\n",
      "46 total farmsite predictions based on farmsites\n",
      "3 farm site predictions containing 4 or more net pen predictions\n",
      "42 net pen predictions within farm sites\n",
      "{'init': 'EPSG:3034'}\n",
      "42 net pen predictions\n",
      "3 farm site predictions\n",
      "final number of predicted net pens: 19\n",
      "final number of predicted farm sites: 1\n",
      "total coordinates (5 per detection): 5\n",
      "country: FRA\n",
      "10352 total SIMRDWN predictions\n",
      "10352 total SIMRDWN predictions\n",
      "2418 total SIMRDWN predictions less than or equal to 55 meters\n",
      "2418 predictions aggregated to 1385 predictions\n",
      "1385 predictions\n",
      "686 total farmsite predictions based on farmsites\n",
      "54 farm site predictions containing 4 or more net pen predictions\n",
      "584 net pen predictions within farm sites\n",
      "{'init': 'EPSG:2154'}\n",
      "584 net pen predictions\n",
      "54 farm site predictions\n",
      "final number of predicted net pens: 21\n",
      "final number of predicted farm sites: 2\n",
      "total coordinates (5 per detection): 10\n",
      "country: ALB\n",
      "2217 total SIMRDWN predictions\n",
      "2217 total SIMRDWN predictions\n",
      "700 total SIMRDWN predictions less than or equal to 55 meters\n",
      "700 predictions aggregated to 296 predictions\n",
      "296 predictions\n",
      "181 total farmsite predictions based on farmsites\n",
      "12 farm site predictions containing 4 or more net pen predictions\n",
      "96 net pen predictions within farm sites\n",
      "{'init': 'EPSG:6962'}\n",
      "96 net pen predictions\n",
      "12 farm site predictions\n",
      "final number of predicted net pens: 70\n",
      "final number of predicted farm sites: 7\n",
      "total coordinates (5 per detection): 35\n"
     ]
    }
   ],
   "source": [
    "#import os\n",
    "import math\n",
    "import fiona \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from geopandas.tools import sjoin\n",
    "from shapely.geometry import Polygon, Point, mapping\n",
    "from explode import explode\n",
    "from coord import coord\n",
    "\n",
    "wgs84= {'init' :'EPSG:4326'}\n",
    "\n",
    "#SET COUNTRY/CRS <-------------------------------------------------------------------------------CHANGE\n",
    "countries = ['TUR', 'EPSG:5637'],['ESP', 'EPSG:2062'],['HRV', 'EPSG:3765'],['ITA', 'EPSG:7794'],['CYP', 'EPSG:6312'],['MLT', 'EPSG:3034'],['FRA', 'EPSG:2154'],['ALB', 'EPSG:6962'] \n",
    "\n",
    "def simrdwn(n):\n",
    "    #open file\n",
    "    f = '../targets_2_simrdwn/' + n[0] + '/'\n",
    "    file = f + 'predictions_' + n[0] + '.csv'\n",
    "    detections = pd.read_csv(file, delimiter=',', header=0)\n",
    "    print('country:', n[0])\n",
    "    print(len(detections), 'total SIMRDWN predictions')\n",
    "\n",
    "    #georeference prediction bounding boxes and convert to centroid\n",
    "    selected = detections\n",
    "\n",
    "    lon_list, lat_list, radius_list, diameter_list = [], [], [], []\n",
    "    for i in range(len(selected)):\n",
    "        img = detections['img_file'].iloc[i]\n",
    "\n",
    "    #extract bottom right coordinate from image name\n",
    "        br_lon = float(img.split('_')[4] + '.' + img.split('_')[5]) #lon = x                                       \n",
    "        br_lat = float(img.split('_')[2] + '.' + img.split('_')[3]) #lat = y\n",
    "\n",
    "        #extract top left coordinate from image name\n",
    "        tl_lon = float(img.split('_')[8] + '.' + (img.split('_')[9]).split('.')[0]) #lon = x\n",
    "        tl_lat = float(img.split('_')[6] + '.' + img.split('_')[7]) #lat = y    \n",
    "\n",
    "    #     #FOR GREECE ONLY - extract bottom right coordinate from image name\n",
    "    #     br_lon = float(img.split('_')[8] + '.' + img.split('_')[9]) #lon = x                                       \n",
    "    #     br_lat = float(img.split('_')[6] + '.' + img.split('_')[7]) #lat = y\n",
    "\n",
    "    #     #extract top left coordinate from image name\n",
    "    #     tl_lon = float(img.split('_')[12] + '.' + (img.split('_')[13]).split('.')[0]) #lon = x\n",
    "    #     tl_lat = float(img.split('_')[10] + '.' + img.split('_')[11]) #lat = y\n",
    "\n",
    "        #image dimensions\n",
    "        img_w = detections['img_width'].iloc[i]\n",
    "        img_h = detections['img_height'].iloc[i]\n",
    "        width = abs(br_lon - tl_lon) \n",
    "        height = abs(tl_lat - br_lat)\n",
    "\n",
    "        #decimal degrees per pixel\n",
    "        res_x = width / img_w #image width\n",
    "        res_y = height / img_h #image height\n",
    "\n",
    "        #res\n",
    "        lat = tl_lat * math.pi / 180\n",
    "        res = 156543.04 * math.cos(lat) / (2 ** 18)\n",
    "\n",
    "        #convert bounding box to centroid\n",
    "        xmin = detections['xmin'].iloc[i]\n",
    "        ymin = detections['ymin'].iloc[i]\n",
    "        xmax = detections['xmax'].iloc[i]\n",
    "        ymax = detections['ymax'].iloc[i]\n",
    "        x = (xmin + xmax) / 2\n",
    "        y = (ymin + ymax) / 2\n",
    "\n",
    "        #convert centroid point to lat/lon   \n",
    "        x_center = tl_lon + (x * res_x) \n",
    "        y_center = tl_lat - (y * res_y) \n",
    "\n",
    "        #estimate radius of detection\n",
    "        w = xmax-xmin \n",
    "        h = ymax-ymin \n",
    "        radius = (((w+h)/2)/4)*1.1\n",
    "        diameter = radius * 2\n",
    "        lon_list.append(x_center)\n",
    "        lat_list.append(y_center)\n",
    "        radius_list.append(radius)\n",
    "        diameter_list.append(diameter)\n",
    "\n",
    "    #add attributes to df\n",
    "    d2 = selected.reset_index(drop=True) #super important\n",
    "    d2 = d2.drop(columns=['label'])\n",
    "    d2['x']=lon_list\n",
    "    d2['y']=lat_list\n",
    "    d2['radius']=np.round(radius_list,2)\n",
    "    d2['diameter']=np.round(diameter_list,2)\n",
    "    print(len(d2), 'total SIMRDWN predictions')\n",
    "\n",
    "    #add geometry information to df \n",
    "    geometry = [Point(i) for i in zip(lon_list, lat_list)]\n",
    "    d2 = gpd.GeoDataFrame(d2, geometry=geometry, crs=wgs84)\n",
    "    d2 = d2.to_crs({'init': n[1]})\n",
    "\n",
    "    #select predictions within search area\n",
    "    # search_area = gpd.read_file('../0_search_areas/4_search_area/search_area_100m_' + n + '.shp')\n",
    "    # search_area = search_area.to_crs({'init': n[1]})\n",
    "\n",
    "    # d2 = sjoin(d2, search_area, how='inner', op='within')\n",
    "    # print(len(d2), 'predictions within search area')\n",
    "\n",
    "    #select predictions by diameter\n",
    "    d = 55\n",
    "    d2 = d2[d2['diameter'] <= d]\n",
    "    geometry = [Point(i) for i in zip(d2['x'], d2['y'])]\n",
    "\n",
    "    d2 = d2[['radius', 'geometry']]\n",
    "    print(len(d2), 'total SIMRDWN predictions less than or equal to', d, 'meters')\n",
    "\n",
    "    #aggregate predictions \n",
    "    buffer = gpd.GeoDataFrame(geometry = d2.buffer(10)) #buffer by 10 meters\n",
    "    buffer['Dissolve'] = 0\n",
    "    buffer_dis = buffer.dissolve(by='Dissolve')\n",
    "    buffer_exploded = explode(buffer_dis)    \n",
    "    print(len(d2), 'predictions aggregated to', len(buffer_exploded), 'predictions')\n",
    "\n",
    "    #calculate mean radius of aggregated predictions\n",
    "    d2_ag = gpd.sjoin(d2, buffer_exploded, how=\"inner\", op='intersects')\n",
    "    centroids = gpd.GeoDataFrame(geometry = buffer_exploded.centroid, crs=wgs84)\n",
    "    centroids['radius']=d2_ag.groupby('index_right')['radius'].mean()\n",
    "    centroids.crs={'init' : n[1]}\n",
    "    print(len(centroids), 'predictions')\n",
    "\n",
    "    #generate farmsite polygons\n",
    "    b = 100\n",
    "    buffer = gpd.GeoDataFrame(geometry = centroids.buffer(b)) #buffer by 100m\n",
    "    buffer['Dissolve'] = 0\n",
    "    buffer_dis = buffer.dissolve(by='Dissolve')\n",
    "    buffer_exploded = explode(buffer_dis)    \n",
    "    buffer_exploded.crs={'init' : n[1]}\n",
    "\n",
    "    #add number of predictions per farmsite to farmsite polygons\n",
    "    count=sjoin(centroids, buffer_exploded, how='inner', op='within')\n",
    "    buffer_exploded['cage count']=count.groupby('index_right')['index_right'].count()\n",
    "    buffer_exploded['cage count']=count.groupby('index_right')['index_right'].count()\n",
    "    buffer_exploded[\"farm ID\"] = buffer_exploded.index + 1 #add farm ID\n",
    "\n",
    "    print(len(buffer_exploded), 'total farmsite predictions based on farmsites')\n",
    "\n",
    "    #select farmsites by number of predictions\n",
    "    p = 4 #number of predictions per farmsite\n",
    "    farmsites = buffer_exploded[buffer_exploded['cage count'] >= p]\n",
    "    print(len(farmsites), 'farm site predictions containing', p, 'or more net pen predictions')\n",
    "\n",
    "    #select predictions by farmsites\n",
    "    select = farmsites\n",
    "    select['predictions'] = 0\n",
    "    select = select.dissolve(by='predictions')\n",
    "    mask = centroids.within(select.loc[0, 'geometry'])\n",
    "    farmsites=farmsites.drop(['predictions'], axis=1)\n",
    "    d2_clip = centroids.loc[mask]\n",
    "\n",
    "    print(len(d2_clip), 'net pen predictions within farm sites')\n",
    "    print(d2_clip.crs)\n",
    "\n",
    "    #add id and farm_id to predictions\n",
    "    d2_clip_id=sjoin(farmsites, d2_clip, how='right', op='intersects')\n",
    "    d2_clip_id=d2_clip_id.reset_index(drop=True)\n",
    "    d2_clip_id[\"cage ID\"] = d2_clip_id.index + 1 \n",
    "    d2_clip_id['diameter']=d2_clip_id['radius'] * 2\n",
    "\n",
    "    d2_clip_id['radius']=round(d2_clip_id['radius'],2)\n",
    "    d2_clip_id['diameter']=round(d2_clip_id['diameter'],2)\n",
    "\n",
    "    d2_clip=d2_clip_id[['farm ID', 'cage ID', 'radius', 'diameter', 'geometry']]\n",
    "    print(len(d2_clip), 'net pen predictions')\n",
    "\n",
    "    #generate farmsite extents\n",
    "    envelope = gpd.GeoDataFrame(geometry = farmsites.envelope)\n",
    "    farmsites2=farmsites.copy()\n",
    "    farmsites2['geometry']=envelope['geometry']\n",
    "    farmsites2=farmsites2[['farm ID', 'cage count', 'geometry']]\n",
    "    print(len(farmsites2), 'farm site predictions')\n",
    "\n",
    "    #exclusion of false positives\n",
    "    path= f + n[0] + '_exclude.kml'\n",
    "    gpd.io.file.fiona.drvsupport.supported_drivers['KML'] = 'rw'\n",
    "    exclude = gpd.read_file(path, driver='KML')\n",
    "    exclude = exclude.to_crs({'init': n[1]})\n",
    "\n",
    "    #create exclusion mask\n",
    "    exclude['Dissolve'] = 0\n",
    "    exclude_dis = exclude.dissolve(by='Dissolve')\n",
    "\n",
    "    #eliminate net pen false positives\n",
    "    mask = ~d2_clip.within(exclude_dis.loc[0, 'geometry'])\n",
    "    d2_clip = d2_clip.loc[mask]\n",
    "    print('final number of predicted net pens:', len(d2_clip))\n",
    "\n",
    "    #eliminate farmsite false positives\n",
    "    mask2 = ~farmsites2.within(exclude_dis.loc[0, 'geometry'])\n",
    "    farmsites2 = farmsites2.loc[mask2]\n",
    "    print('final number of predicted farm sites:', len(farmsites2))\n",
    "\n",
    "    #generate farmsite centroids\n",
    "    farmsites3 = farmsites2.copy()\n",
    "    farm_pts = gpd.GeoDataFrame(farmsites3, geometry = farmsites3.centroid)\n",
    "    \n",
    "    #generate buffer and envelope for bing aquistion\n",
    "    farm_pts_2 = farm_pts.copy()\n",
    "    centroid_buffer = gpd.GeoDataFrame(geometry = farm_pts_2.buffer(500))\n",
    "    envelope = gpd.GeoDataFrame(farmsites3, geometry = centroid_buffer.envelope)\n",
    "    envelope = envelope['geometry'].to_crs(epsg=4326)\n",
    "    #extract lat/long for each square polygon (envelope)\n",
    "    coord_list = []\n",
    "    for i in envelope.index:\n",
    "        coords = (mapping(envelope.geometry[i])['coordinates'])\n",
    "        coord_list.append(coords)\n",
    "\n",
    "    #generate CSVs of bing targets and index\n",
    "    #combine x/y point groups\n",
    "    coord_all = []\n",
    "    for i in range(len(coord_list)):\n",
    "        coord_group = coord(coord_list[i]) #function to extract and format x/y points\n",
    "        coord_all.append(coord_group) \n",
    "    targets = pd.concat(coord_all)\n",
    "    print('total coordinates (5 per detection):', len(targets))\n",
    "\n",
    "    targets.to_csv(f + n[0] + '.csv', index = None, header=True)\n",
    "\n",
    "    index = pd.DataFrame(envelope.index)\n",
    "    index = index[0] + 1\n",
    "    index.to_csv(f + n[0] + '_index.csv', index = None, header=False)\n",
    "\n",
    "    #generate net pen buffers\n",
    "    def buffer(row):\n",
    "         return row.geometry.buffer(row.radius)   \n",
    "    d2_clip2 = d2_clip.copy()\n",
    "    d2_clip2.crs\n",
    "    buff = d2_clip2['geometry'] = d2_clip2.apply(buffer, axis=1)\n",
    "    circles = gpd.GeoDataFrame(d2_clip2, geometry = buff, crs={'init': n[1]})\n",
    "    \n",
    "    # #export all centroids\n",
    "    d2 = d2.to_crs({'init': n[1]})\n",
    "    d2.to_file(f + n[0] + '_simrdwn.shp')\n",
    "    d2['geometry'] = d2['geometry'].to_crs(epsg=4326)\n",
    "    d2.to_file(f + n[0] + '_simrdwn.geojson', driver='GeoJSON')\n",
    "\n",
    "    # #export buffered centroids\n",
    "    circles.to_file(f + n[0] + '_simrdwn_pens.shp')\n",
    "    circles['geometry'] = circles['geometry'].to_crs(epsg=4326)\n",
    "    circles.to_file(f + n[0] + '_simrdwn_pens.geojson', driver='GeoJSON')\n",
    "\n",
    "    #export centroids within farmsites\n",
    "    d2_clip.to_file(f + n[0] + '_simrdwn_pts.shp')\n",
    "    d2_clip['geometry'] = d2_clip['geometry'].to_crs(epsg=4326)\n",
    "    d2_clip.to_file(f + n[0] + '_simrdwn_pts.geojson', driver='GeoJSON')\n",
    "\n",
    "    # #export farmsites extents\n",
    "    farmsites2.to_file(f + n[0] + '_simrdwn_farmsites_ext.shp')\n",
    "    farmsites2['geometry'] = farmsites2['geometry'].to_crs(epsg=4326)\n",
    "    farmsites2.to_file(f + n[0] + '_simrdwn_farmsites_ext.geojson', driver='GeoJSON')\n",
    "\n",
    "    # #export farmsites points\n",
    "    farm_pts=farm_pts_2\n",
    "    farm_pts.to_file(f + n[0] + '_simrdwn_farm_pts.shp')\n",
    "    farm_pts['geometry'] = farm_pts['geometry'].to_crs(epsg=4326)\n",
    "    farm_pts.to_file(f + n[0] + '_simrdwn_farm_pts.geojson', driver='GeoJSON')\n",
    "\n",
    "for i in countries:\n",
    "    simrdwn(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
