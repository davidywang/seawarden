for (i in index(sites)){
column <- i + 4
export <- population %>% select(1, 2, column, 3, 4)
export[9, 3] = pre_sim
site <- (population %>% select(column))[1,]
output <- paste0(rac_folder, 'site_', site, '/Bass_population/Inputs/Parameters/Population.csv')
write.table(export, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
#generate Parameters.csv for each site
for (i in sites){
export <- parameters %>% select(1, 2, 5, 3, 4) #5 prep parameters
output <- paste0(rac_folder, 'site_', i, '/Bass_population/Inputs/Parameters/Parameters.csv')
write.table(export, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
#generate Feeding.csv for each site
for (i in sites){
output <- paste0(rac_folder, 'site_', i, '/Bass_population/Inputs/Forcings/Feeding.csv')
write.table(feeding_prep, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
#generate Management.csv for each site
for (i in sites){
export <- management %>% select(1, 2, 3)
output <- paste0(rac_folder, 'site_', i, '/Bass_population/Inputs/Population_management/Management.csv')
write.table(export, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
#generate Food_Characterization.csv for each site
for (i in sites){
export <- food %>% select(2, 1)
export <- export[-1,] #drop header
output <- paste0(rac_folder, 'site_', i, '/Bass_population/Inputs/Forcings/Food_Characterization.csv')
write.table(export, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
#first model run to generate feeding tables
for (i in sites_2){
userpath <- paste0(rac_folder, "site_", i)
setwd(userpath) #working directory
forcings <- Bass_pop_dataloader(userpath) #load environmental variables
output <- Bass_pop_main(userpath, forcings)} #run growth model
#generate final feeding tables
feeding <- function(rac_folder, i){
site_folder <- paste0('site_', i, '/Bass_population/Outputs/Out_csv/')
ingestion <- read.csv(paste0(rac_folder, site_folder, 'actual_ingestion.csv'), header=TRUE, sep=",")
ingestion <- ingestion %>% select(V1)
date <- feeding_prep %>% select(date)
date <- date$date[1:nrow(ingestion)]
compiled <- cbind(date, ingestion)
name <- paste0(rac_folder, 'feeding_files/site_', i, '_feeding.csv')
write.table(compiled, file = name, row.names=FALSE, col.names = TRUE, sep=",")}
for (i in sites){
feeding(rac_folder, i)}
#load data for final model run
#generate Population.csv for each site
for (i in index(sites)){
column <- i + 4
export <- population %>% select(1, 2, column, 3, 4)
export[9, 3] = main_sim
site <- (population %>% select(column))[1,]
output <- paste0(rac_folder, 'site_', site, '/Bass_population/Inputs/Parameters/Population.csv')
write.table(export, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
#generate Parameters.csv for each site
for (i in sites){
export <- parameters %>% select(1, 2, 6, 3, 4) #final parameters
output <- paste0(rac_folder, 'site_', i, '/Bass_population/Inputs/Parameters/Parameters.csv')
write.table(export, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
#generate Feeding.csv for each site
for (i in sites){
feed <- read.csv(paste0(rac_folder, 'feeding_files/site_', i, '_feeding.csv'))
output <- paste0(rac_folder, 'site_', i, '/Bass_population/Inputs/Forcings/Feeding.csv')
write.table(feed, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
for (i in sites_2){
userpath <- paste0(rac_folder, "site_", i)
setwd(userpath) #working directory
forcings <- Bass_pop_dataloader(userpath) #load environmental variables
output <- Bass_pop_main(userpath, forcings)} #run growth model
library(RAC)
library(dplyr)
library(zoo) #index function
#command + shift + c
trace(Bass_pop_main,edit=T) #delete selector = "y"
#generate prep files for all sites
farmsites <- read.csv('/Users/Zack/0_seawarden/r_rac/master_inventory - Farm_Sites.csv', header=TRUE, sep=",")
sites <- as.vector(farmsites$farm_site)
#select sites to model
sites_2 <- list(23, 71, 92, 165, 172, 219) #study sites
sites_2 <- list(23, 71, 92)
# sites_2 <- list(0, 1, 2)
# sites_2 <- list(23)
#specify number of simulations 1) feeding 2), full simulation
pre_sim <- 50
main_sim <- 5000
pre_sim <- 6
main_sim <- 7
#load sst files
sst_folder <- '/Users/Zack/0_thesis_sst/ghrsst_csv/'
sst_list <- list.files(sst_folder, pattern = '.csv')
#load master files
rac_folder <- "/Users/Zack/0_seawarden/r_rac/rac_seabass/"
master_files <- paste0(rac_folder, 'master_files/master_RAC-seabass - ')
#prep files to generate feeding tables
feeding_prep <- read.csv(paste0(master_files, 'Feeding_Prep.csv'), header=TRUE, sep=",")
#files for both steps
population <- read.csv(paste0(master_files, 'Population_test.csv'), header=FALSE, sep=",")
parameters <- read.csv(paste0(master_files, 'Parameters.csv'), header=FALSE, sep=",")
management <- read.csv(paste0(master_files, 'Management.csv'), header=FALSE, sep=",")
food <- read.csv(paste0(master_files, 'Food_Characterization.csv'), header=FALSE, sep=",")
create folder for each site, #add SST data
library(RAC)
library(dplyr)
library(zoo) #index function
#command + shift + c
trace(Bass_pop_main,edit=T) #delete selector = "y"
#generate prep files for all sites
farmsites <- read.csv('/Users/Zack/0_seawarden/r_rac/master_inventory - Farm_Sites.csv', header=TRUE, sep=",")
sites <- as.vector(farmsites$farm_site)
#select sites to model
sites_2 <- list(23, 71, 92, 165, 172, 219) #study sites
sites_2 <- list(23, 71, 92)
# sites_2 <- list(0, 1, 2)
# sites_2 <- list(23)
#specify number of simulations 1) feeding 2), full simulation
pre_sim <- 50
main_sim <- 5000
pre_sim <- 6
main_sim <- 7
#load sst files
sst_folder <- '/Users/Zack/0_thesis_sst/ghrsst_csv/'
sst_list <- list.files(sst_folder, pattern = '.csv')
#load master files
rac_folder <- "/Users/Zack/0_seawarden/r_rac/rac_seabass/"
master_files <- paste0(rac_folder, 'master_files/master_RAC-seabass - ')
#prep files to generate feeding tables
feeding_prep <- read.csv(paste0(master_files, 'Feeding_Prep.csv'), header=TRUE, sep=",")
#files for both steps
population <- read.csv(paste0(master_files, 'Population_test.csv'), header=FALSE, sep=",")
parameters <- read.csv(paste0(master_files, 'Parameters.csv'), header=FALSE, sep=",")
management <- read.csv(paste0(master_files, 'Management.csv'), header=FALSE, sep=",")
food <- read.csv(paste0(master_files, 'Food_Characterization.csv'), header=FALSE, sep=",")
#create folder for each site, #add SST data
for (i in sites){
#create a folder for each site
site_folder <- paste0(rac_folder, 'site_', i, '/')
dir.create(site_folder)
#create RAC folders for each site
Bass_pop_skeleton(site_folder)
#add SST data
orglocation <- paste0(sst_folder, i, '_sst.csv')
newlocation <- paste0(site_folder, 'Bass_population/Inputs/Forcings/')
file.copy(from=orglocation, to=newlocation, overwrite = TRUE, recursive = FALSE, copy.mode = TRUE)
file.remove(paste0(newlocation, 'Water_temperature.csv'))
file.rename(paste0(newlocation, i, '_sst.csv'), paste0(newlocation, 'Water_temperature.csv'))}
#generate Population.csv for each site
for (i in index(sites)){
column <- i + 4
export <- population %>% select(1, 2, column, 3, 4)
export[9, 3] = pre_sim
site <- (population %>% select(column))[1,]
output <- paste0(rac_folder, 'site_', site, '/Bass_population/Inputs/Parameters/Population.csv')
write.table(export, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
#generate Parameters.csv for each site
for (i in sites){
export <- parameters %>% select(1, 2, 5, 3, 4) #5 prep parameters
output <- paste0(rac_folder, 'site_', i, '/Bass_population/Inputs/Parameters/Parameters.csv')
write.table(export, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
#generate Feeding.csv for each site
for (i in sites){
output <- paste0(rac_folder, 'site_', i, '/Bass_population/Inputs/Forcings/Feeding.csv')
write.table(feeding_prep, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
#generate Management.csv for each site
for (i in sites){
export <- management %>% select(1, 2, 3)
output <- paste0(rac_folder, 'site_', i, '/Bass_population/Inputs/Population_management/Management.csv')
write.table(export, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
#generate Food_Characterization.csv for each site
for (i in sites){
export <- food %>% select(2, 1)
export <- export[-1,] #drop header
output <- paste0(rac_folder, 'site_', i, '/Bass_population/Inputs/Forcings/Food_Characterization.csv')
write.table(export, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
#first model run to generate feeding tables
for (i in sites_2){
userpath <- paste0(rac_folder, "site_", i)
setwd(userpath) #working directory
forcings <- Bass_pop_dataloader(userpath) #load environmental variables
output <- Bass_pop_main(userpath, forcings)} #run growth model
#generate final feeding tables
feeding <- function(rac_folder, i){
site_folder <- paste0('site_', i, '/Bass_population/Outputs/Out_csv/')
ingestion <- read.csv(paste0(rac_folder, site_folder, 'actual_ingestion.csv'), header=TRUE, sep=",")
ingestion <- ingestion %>% select(V1)
date <- feeding_prep %>% select(date)
date <- date$date[1:nrow(ingestion)]
compiled <- cbind(date, ingestion)
name <- paste0(rac_folder, 'feeding_files/site_', i, '_feeding.csv')
write.table(compiled, file = name, row.names=FALSE, col.names = TRUE, sep=",")}
for (i in sites){
feeding(rac_folder, i)}
#load data for final model run
#generate Population.csv for each site
for (i in index(sites)){
column <- i + 4
export <- population %>% select(1, 2, column, 3, 4)
export[9, 3] = main_sim
site <- (population %>% select(column))[1,]
output <- paste0(rac_folder, 'site_', site, '/Bass_population/Inputs/Parameters/Population.csv')
write.table(export, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
#generate Parameters.csv for each site
for (i in sites){
export <- parameters %>% select(1, 2, 6, 3, 4) #final parameters
output <- paste0(rac_folder, 'site_', i, '/Bass_population/Inputs/Parameters/Parameters.csv')
write.table(export, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
#generate Feeding.csv for each site
for (i in sites){
feed <- read.csv(paste0(rac_folder, 'feeding_files/site_', i, '_feeding.csv'))
output <- paste0(rac_folder, 'site_', i, '/Bass_population/Inputs/Forcings/Feeding.csv')
write.table(feed, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
for (i in sites_2){
userpath <- paste0(rac_folder, "site_", i)
setwd(userpath) #working directory
forcings <- Bass_pop_dataloader(userpath) #load environmental variables
output <- Bass_pop_main(userpath, forcings)} #run growth model
library(dplyr)
library(raster)
library(sp)
library(sf)
library(rWind)
#install.packages("rWind")
#function to crop raster to area of interest, converts raster to point
crop_tool <- function(image_file, target){
#opens raster file, clips raster to target (target is opened in a prior step)
raster_crop <- crop(raster(image_file), target)
#raster clip is convereted to a point
pts <- rasterToPoints(raster_crop)
#points converted to a df
pts_df <- as.data.frame(pts)
#mean calculated to result in just one measurement
mean(pts_df[,3])}
current_tool <- function(v_folder, u_folder, target, output){
#added here for parallel processing
library(raster)
library(rWind)
#list of tif files in folder
v_list <- list.files(v_folder, pattern = '.tif')
u_list <- list.files(u_folder, pattern = '.tif')
daily_u = list()
daily_v = list()
date = list()
#for (i in 1:3){
for (i in 1:365){
v_file <- paste0(v_folder, v_list[i])
u_file <- paste0(u_folder, u_list[i])
v <- crop_tool(v_file, target)
u <- crop_tool(u_file, target)
daily_u[[i]] <- u
daily_v[[i]] <- v
day <- substr(u_list[i], 19, 20)
month <- substr(u_list[i], 16, 17)
year <- substr(u_list[i], 11, 14)
date[[i]] <- paste0(day, "/", month, "/", year)}
daily_v = do.call(rbind, daily_v)
daily_u = do.call(rbind, daily_u)
date = data.frame(do.call(rbind, date))
#daily_v <- as.data.frame(daily_v)
#daily_u <- as.data.frame(daily_u)
#colnames(date) <- c("date")
#colnames(daily_v) <- c("v")
#colnames(daily_u) <- c("u")
#combine
daily <- cbind(date, uv2ds(u=daily_u, v=daily_v))
#daily <- cbind(date, daily_v, daily_u)
#rename columns
daily <- daily %>% rename(date=1, dir=2, speed=3)
#create output filename and export as csv
df <-as.data.frame(target)
filename <- paste0(output, paste0(df['farm_id']), '_medsea_current.csv')
#create output file
#write.csv(daily, file=filename, row.names = FALSE)}
write.table(daily, file = filename, row.names=FALSE, col.names = TRUE, sep=",")}
#load ocean current data
v_folder <- '/Users/Zack/0_thesis_ocean_current_2/medsea_vo_2018_tif/'
u_folder <- '/Users/Zack/0_thesis_ocean_current_2/medsea_uo_2018_tif/'
#output folder
output <- '/Users/Zack/0_thesis_ocean_current_2/medsea_current_2018_csv/'
#output <- '/Users/Zack/Desktop/test/'
#load shapefile of farm sites
#targets <- '/Users/Zack/0_GIS_Greece/blue_bridge/fishcages_Greece_farm_pts.shp'
targets <- '/Users/Zack/0_greece/blue_bridge/fishcages_Greece_farm_pts_1m_3.shp'
targets <- st_read(targets)
#single use
#current_tool(v_folder, u_folder, targets[15,], output)
#loop to create u, v, direction and speed csv for all farm sites
#for (i in 1:nrow(as.data.frame(targets))){current_tool(v_folder, u_folder, targets[i,], output)}
#parallel processing
#http://pablobarbera.com/ECPR-SC105/code/02-parallel-computing.html
#https://nceas.github.io/oss-lessons/parallel-computing-in-r/parallel-computing-in-r.html
library(foreach)
library(doParallel)
#select numbrer of cores
myCluster <- makeCluster(3, type = "PSOCK")
#activate clusters
registerDoParallel(myCluster)
#parallel process
sites <- 1:nrow(as.data.frame(targets))
foreach(i = sites) %dopar% current_tool(v_folder, u_folder, targets[i,], output)
library(dplyr)
library(raster)
library(sp)
library(sf)
#install.packages("rWind")
library(rWind)
library(foreach)
library(doParallel)
#load ocean current data
v_folder <- '/Users/Zack/0_thesis_ocean_current_2/medsea_vo_2018_tif/'
u_folder <- '/Users/Zack/0_thesis_ocean_current_2/medsea_uo_2018_tif/'
#output folder
output <- '/Users/Zack/0_thesis_ocean_current_2/medsea_current_2018_csv/'
#input folders - for combine
folder_1 <- '/Users/Zack/0_thesis_ocean_current_2/medsea_current_2018_csv/'
folder_2 <- '/Users/Zack/0_thesis_ocean_current_2/medsea_current_2019_csv/'
#output folder - for combine
folder_3 <- '/Users/Zack/0_thesis_ocean_current/medsea_current_csv/'
#load shapefile of farm sites
#targets <- '/Users/Zack/0_GIS_Greece/blue_bridge/fishcages_Greece_farm_pts.shp'
targets <- '/Users/Zack/0_greece/blue_bridge/fishcages_Greece_farm_pts_1m_3.shp'
targets <- st_read(targets)
#function to crop raster to area of interest, converts raster to point
crop_tool <- function(image_file, target){
#opens raster file, clips raster to target (target is opened in a prior step)
raster_crop <- crop(raster(image_file), target)
#raster clip is convereted to a point
pts <- rasterToPoints(raster_crop)
#points converted to a df
pts_df <- as.data.frame(pts)
#mean calculated to result in just one measurement
mean(pts_df[,3])}
current_tool <- function(v_folder, u_folder, target, output){
#added here for parallel processing
library(raster)
library(rWind)
#list of tif files in folder
v_list <- list.files(v_folder, pattern = '.tif')
u_list <- list.files(u_folder, pattern = '.tif')
daily_u = list()
daily_v = list()
date = list()
#for (i in 1:3){
for (i in 1:365){
v_file <- paste0(v_folder, v_list[i])
u_file <- paste0(u_folder, u_list[i])
v <- crop_tool(v_file, target)
u <- crop_tool(u_file, target)
daily_u[[i]] <- u
daily_v[[i]] <- v
day <- substr(u_list[i], 19, 20)
month <- substr(u_list[i], 16, 17)
year <- substr(u_list[i], 11, 14)
date[[i]] <- paste0(day, "/", month, "/", year)}
daily_v = do.call(rbind, daily_v)
daily_u = do.call(rbind, daily_u)
date = data.frame(do.call(rbind, date))
#daily_v <- as.data.frame(daily_v)
#daily_u <- as.data.frame(daily_u)
#colnames(date) <- c("date")
#colnames(daily_v) <- c("v")
#colnames(daily_u) <- c("u")
#combine
daily <- cbind(date, uv2ds(u=daily_u, v=daily_v))
#daily <- cbind(date, daily_v, daily_u)
#rename columns
daily <- daily %>% rename(date=1, dir=2, speed=3)
#create output filename and export as csv
df <-as.data.frame(target)
filename <- paste0(output, paste0(df['farm_id']), '_medsea_current.csv')
#create output file
#write.csv(daily, file=filename, row.names = FALSE)}
write.table(daily, file = filename, row.names=FALSE, col.names = TRUE, sep=",")}
#single use
#current_tool(v_folder, u_folder, targets[15,], output)
#loop to create u, v, direction and speed csv for all farm sites
#for (i in 1:nrow(as.data.frame(targets))){current_tool(v_folder, u_folder, targets[i,], output)}
#function to combine files
combine <- function(folder_1, folder_2, folder_3){
#read csv files
csv_1 <- read.delim(paste0(folder_1, list_1[i]), sep = ',', stringsAsFactors = F, header = FALSE)
csv_2 <- read.delim(paste0(folder_2, list_1[i]), sep = ',', stringsAsFactors = F, header = FALSE)
#create output filename
output <- paste0(folder_3, paste0(list_1[i]))
#merge dataframes and export file
write.table(rbind(csv_1, csv_2), file = paste0(folder_3, paste0(list_1[i])), row.names=FALSE, col.names = FALSE, sep=",")}
#combine 2018 and 2019 csv files
#list files in folders
list_1 <- list.files(folder_1, pattern = '.csv')
list_2 <- list.files(folder_2, pattern = '.csv')
#parallel processing
#http://pablobarbera.com/ECPR-SC105/code/02-parallel-computing.html
#https://nceas.github.io/oss-lessons/parallel-computing-in-r/parallel-computing-in-r.html
#select numbrer of cores
myCluster <- makeCluster(3, type = "PSOCK")
#activate clusters
registerDoParallel(myCluster)
#parallel process
sites <- 1:nrow(as.data.frame(targets))
foreach(i = sites) %dopar% current_tool(v_folder, u_folder, targets[i,], output)
date
length(date)
length(u_list)
library(dplyr)
library(raster)
library(sp)
library(sf)
#install.packages("rWind")
library(rWind)
library(foreach)
library(doParallel)
#load ocean current data
v_folder <- '/Users/Zack/0_thesis_ocean_current_2/medsea_vo_2018_tif/' #or 2019
u_folder <- '/Users/Zack/0_thesis_ocean_current_2/medsea_uo_2018_tif/' #or 2019
#output folder
output <- '/Users/Zack/0_thesis_ocean_current_2/medsea_current_2018_csv/' #or 2019
#input folders - for combine
folder_1 <- '/Users/Zack/0_thesis_ocean_current_2/medsea_current_2018_csv/'
folder_2 <- '/Users/Zack/0_thesis_ocean_current_2/medsea_current_2019_csv/'
#output folder - for combine
folder_3 <- '/Users/Zack/0_thesis_ocean_current/medsea_current_csv/'
#load shapefile of farm sites
#targets <- '/Users/Zack/0_GIS_Greece/blue_bridge/fishcages_Greece_farm_pts.shp'
targets <- '/Users/Zack/0_greece/blue_bridge/fishcages_Greece_farm_pts_1m_3.shp'
targets <- st_read(targets)
#function to crop raster to area of interest, converts raster to point
crop_tool <- function(image_file, target){
#opens raster file, clips raster to target (target is opened in a prior step)
raster_crop <- crop(raster(image_file), target)
#raster clip is convereted to a point
pts <- rasterToPoints(raster_crop)
#points converted to a df
pts_df <- as.data.frame(pts)
#mean calculated to result in just one measurement
mean(pts_df[,3])}
targets
targets[1]
targets[,1]
targets[1,]
library(dplyr)
library(raster)
library(sp)
library(sf)
#install.packages("rWind")
library(rWind)
library(foreach)
library(doParallel)
#load ocean current data
v_folder <- '/Users/Zack/0_thesis_ocean_current_2/medsea_vo_2018_tif/' #or 2019
u_folder <- '/Users/Zack/0_thesis_ocean_current_2/medsea_uo_2018_tif/' #or 2019
#output folder
output <- '/Users/Zack/0_thesis_ocean_current_2/medsea_current_2018_csv/' #or 2019
#input folders - for combine
folder_1 <- '/Users/Zack/0_thesis_ocean_current_2/medsea_current_2018_csv/'
folder_2 <- '/Users/Zack/0_thesis_ocean_current_2/medsea_current_2019_csv/'
#output folder - for combine
folder_3 <- '/Users/Zack/0_thesis_ocean_current/medsea_current_csv/'
#load shapefile of farm sites
#targets <- '/Users/Zack/0_GIS_Greece/blue_bridge/fishcages_Greece_farm_pts.shp'
targets <- '/Users/Zack/0_greece/blue_bridge/fishcages_Greece_farm_pts_1m_3.shp'
targets <- st_read(targets)
targets <- targets[1,]
#function to crop raster to area of interest, converts raster to point
crop_tool <- function(image_file, target){
#opens raster file, clips raster to target (target is opened in a prior step)
raster_crop <- crop(raster(image_file), target)
#raster clip is convereted to a point
pts <- rasterToPoints(raster_crop)
#points converted to a df
pts_df <- as.data.frame(pts)
#mean calculated to result in just one measurement
mean(pts_df[,3])}
current_tool <- function(v_folder, u_folder, target, output){
#added here for parallel processing
library(raster)
library(rWind)
#list of tif files in folder
v_list <- list.files(v_folder, pattern = '.tif')
u_list <- list.files(u_folder, pattern = '.tif')
daily_u = list()
daily_v = list()
date = list()
#for (i in 1:3){
for (i in 1:length(date)){
v_file <- paste0(v_folder, v_list[i])
u_file <- paste0(u_folder, u_list[i])
v <- crop_tool(v_file, target)
u <- crop_tool(u_file, target)
daily_u[[i]] <- u
daily_v[[i]] <- v
day <- substr(u_list[i], 19, 20)
month <- substr(u_list[i], 16, 17)
year <- substr(u_list[i], 11, 14)
date[[i]] <- paste0(day, "/", month, "/", year)}
length(date)
daily_v = do.call(rbind, daily_v)
daily_u = do.call(rbind, daily_u)
date = data.frame(do.call(rbind, date))
#daily_v <- as.data.frame(daily_v)
#daily_u <- as.data.frame(daily_u)
#colnames(date) <- c("date")
#colnames(daily_v) <- c("v")
#colnames(daily_u) <- c("u")
#combine
daily <- cbind(date, uv2ds(u=daily_u, v=daily_v))
#daily <- cbind(date, daily_v, daily_u)
#rename columns
daily <- daily %>% rename(date=1, dir=2, speed=3)
#create output filename and export as csv
df <-as.data.frame(target)
filename <- paste0(output, paste0(df['farm_id']), '_medsea_current.csv')
#create output file
#write.csv(daily, file=filename, row.names = FALSE)}
write.table(daily, file = filename, row.names=FALSE, col.names = TRUE, sep=",")}
