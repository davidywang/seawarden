---
title: "data prep MEDSEA"
author: "Zack Dinh"
date: "August 30, 2019"
output: html_document
---

```{r include=FALSE}
library(dplyr)
library(raster)
library(sp)
library(sf)

#install.packages("rWind")
library(rWind)

library(foreach)
library(doParallel)

#load ocean current data
v_folder_18 <- '/Users/Zack/0_thesis_ocean_current_2/medsea_vo_2018_tif/' #or 2018
u_folder_18 <- '/Users/Zack/0_thesis_ocean_current_2/medsea_uo_2018_tif/' #or 2018
v_folder_19 <- '/Users/Zack/0_thesis_ocean_current_2/medsea_vo_2019_tif/' #or 2019
u_folder_19 <- '/Users/Zack/0_thesis_ocean_current_2/medsea_uo_2019_tif/' #or 2019

#output folder
output_18 <- '/Users/Zack/0_thesis_ocean_current_2/medsea_current_2018_csv/' #for 2018
output_19 <- '/Users/Zack/0_thesis_ocean_current_2/medsea_current_2018_csv/' #for 2019

#input folders - for combine
folder_1 <- '/Users/Zack/0_thesis_ocean_current_2/medsea_current_2018_csv/'
folder_2 <- '/Users/Zack/0_thesis_ocean_current_2/medsea_current_2019_csv/'

#output folder - for combine
folder_3 <- '/Users/Zack/0_thesis_ocean_current_2/medsea_current_csv/'
```

```{r}
#load shapefile of farm sites
targets <- '/Users/Zack/0_greece/blue_bridge/farm_pts_500m_sq_current.shp'
targets <- st_read(targets)

sites <- 1:nrow(as.data.frame(targets))
```

```{r}
#function to crop raster to area of interest, converts raster to point
crop_tool <- function(image_file, target){
  
  #opens raster file, clips raster to target (target is opened in a prior step)
  raster_crop <- crop(raster(image_file), target) 
  
  #raster clip is convereted to a point
  pts <- rasterToPoints(raster_crop) 
  
  #points converted to a df
  pts_df <- as.data.frame(pts) 
  
  #mean calculated to result in just one measurement
  mean(pts_df[,3])} 
```

```{r}
current_tool <- function(v_folder, u_folder, target, output){ 

  #added here for parallel processing
  library(raster)
  library(rWind)
  
  #list of tif files in folder
  v_list <- list.files(v_folder, pattern = '.tif')
  u_list <- list.files(u_folder, pattern = '.tif')
  
  daily_u = list()
  daily_v = list()
  date = list()

  #for (i in 1:1){
  for (i in 1:length(v_list)){

      v_file <- paste0(v_folder, v_list[i])
      u_file <- paste0(u_folder, u_list[i])

      v <- crop_tool(v_file, target)
      u <- crop_tool(u_file, target)

      daily_u[[i]] <- u
      daily_v[[i]] <- v

      day <- substr(u_list[i], 19, 20)
      month <- substr(u_list[i], 16, 17)
      year <- substr(u_list[i], 11, 14)

      date[[i]] <- paste0(day, "/", month, "/", year)}
    
  daily_v = do.call(rbind, daily_v)
  daily_u = do.call(rbind, daily_u)
  date = data.frame(do.call(rbind, date))
  
  #daily_v <- as.data.frame(daily_v)
  #daily_u <- as.data.frame(daily_u)
  
  #colnames(date) <- c("date")
  #colnames(daily_v) <- c("v")
  #colnames(daily_u) <- c("u")
  
  #combine
  daily <- cbind(date, uv2ds(u=daily_u, v=daily_v))
  #daily <- cbind(date, daily_v, daily_u)
  
  #rename columns
  daily <- daily %>% rename(date=1, dir=2, speed=3)
  
  #create output filename and export as csv
  df <-as.data.frame(target)
  filename <- paste0(output, paste0(df['farm_id']), '_medsea_current.csv')
  
  #create output file
  #write.csv(daily, file=filename, row.names = FALSE)}
  write.table(daily, file = filename, row.names=FALSE, col.names = TRUE, sep=",")}
```

```{r}
#single use
#current_tool(v_folder_18, u_folder_18, targets[1,], output_18)

sites <-sites[13:50]

#loop to create u, v, direction and speed csv for all farm sites
for (i in sites){current_tool(v_folder_18, u_folder_18, targets[i,], output_18)}

targets <- '/Users/Zack/0_greece/blue_bridge/farm_pts_500m_sq_current.shp'
targets <- st_read(targets)
sites <- 1:nrow(as.data.frame(targets))

for (i in sites){current_tool(v_folder_19, u_folder_19, targets[i,], output_19)}
```

```{r}
#does not work atm

#parallel processing
# myCluster <- makeCluster(4, type = "PSOCK") #select numbrer of cores
# 
# registerDoParallel(myCluster) #activate clusters
# foreach(i = sites) %dopar% current_tool(v_folder_18, u_folder_18, targets[i,], output_18) #parallel process - 2018 
# stopCluster(myCluster) #deactivate clusters
# 
# registerDoParallel(myCluster) #activate clusters
# foreach(i = sites) %dopar% current_tool(v_folder_19, u_folder_19, targets[i,], output_19) #parallel process - 2019
# stopCluster(myCluster) #deactivate clusters
```

```{r}
#combine 2018 and 2019 csv files

#function to combine files
combine <- function(folder_1, folder_2, folder_3){

  #read csv files
  csv_1 <- read.delim(paste0(folder_1, list_1[i]), sep = ',', stringsAsFactors = F, header = FALSE)
  csv_2 <- read.delim(paste0(folder_2, list_1[i]), sep = ',', stringsAsFactors = F, header = FALSE)

  #create output filename
  output <- paste0(folder_3, paste0(list_1[i]))
  
  #merge dataframes and export file
  write.table(rbind(csv_1, csv_2), file = paste0(folder_3, paste0(list_1[i])), row.names=FALSE, col.names = FALSE, sep=",")}

#list files in folders
list_1 <- list.files(folder_1, pattern = '.csv')
list_2 <- list.files(folder_2, pattern = '.csv')

#combine SST csv files
for (i in 1:(length(list_1))){combine(folder_1, folder_2, folder_3)}
```
