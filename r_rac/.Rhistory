#load csv files
id <- unlist(strsplit(i, "_"))[2]
harvest <-  read.csv(paste0(rac_folder, 'site_', id, site_folder, 'Days_to_commercial_size.csv'))
compiled <- read.csv(paste0(rac_folder, 'output_compiled/', i), header=TRUE, sep=",")
#extract columns
harvest <- harvest %>% select(3)
harvest <- harvest[[1]]
#sum rows by days of harvest
compiled <- compiled[1:harvest,] %>% select(2, 4, 6, 8, 10, 12)
compiled <- round(colSums(compiled))
compiled <- as.vector(c(id, compiled, harvest))}
#combine all
names <- c("site_ID", "faeces_c", "faeces_l", "faeces_p", "feed_c", "feed_l", "feed_p", "harvest day") #colnames
#bream
sites <- list.files(paste0(rac_folder, 'output_compiled/'), pattern = '.csv')
combined = list()
for (i in sites){combined[[i]] <- compiler_all(rac_folder, site_folder, i)}
combined_df<-data.frame(do.call(rbind, combined))
colnames(combined_df) <- names
#export dataframe as csv
write.table(combined_df, file = paste0('./combined_bream.csv'), row.names=FALSE, col.names = TRUE, sep=",")
#bass
sites <- list.files(paste0(rac_folder_2, 'output_compiled/'), pattern = '.csv')
combined = list()
for (i in sites){combined[[i]] <- compiler_all(rac_folder_2, site_folder_2, i)}
combined_df<-data.frame(do.call(rbind, combined))
colnames(combined_df) <- names
#export dataframe as csv
write.table(combined_df, file = paste0('./combined_seabass.csv'), row.names=FALSE, col.names = TRUE, sep=",")
library(dplyr)
#create one csv per farm site
farmsites <- read.csv('/Users/Zack/0_seawarden/r_rac/master_inventory - Farm_Sites.csv', header=TRUE, sep=",")
sites <- as.vector(farmsites$farm_site)
#rac_folder <- '/Users/Zack/0_rac/rac_bream/'
rac_folder <- "/Users/Zack/0_seawarden/r_rac/rac_bream/"
site_folder <- '/Bream_population/Outputs/Out_csv/'
#rac_folder_2 <- '/Users/Zack/0_rac/rac_seabass/'
rac_folder_2 <- "/Users/Zack/0_seawarden/r_rac/rac_seabass/"
site_folder_2 <- '/Bass_population/Outputs/Out_csv/'
#function to combine RAC predictions from one farm site in to one csv file
compiler <- function(rac_folder, site_folder, i){
filepath <- paste0(rac_folder, 'site_', i, site_folder)
#load csv files
faeces_c <- read.csv(paste0(filepath, 'faeces_production_Carbohydrates.csv'), header=TRUE, sep=",")
faeces_l <- read.csv(paste0(filepath, 'faeces_production_Lipids.csv'), header=TRUE, sep=",")
faeces_p <- read.csv(paste0(filepath, 'faeces_production_Proteins.csv'), header=TRUE, sep=",")
feed_c <- read.csv(paste0(filepath, 'wasted_feed_Carbohydrates.csv'), header=TRUE, sep=",")
feed_l <- read.csv(paste0(filepath, 'wasted_feed_Lipids.csv'), header=TRUE, sep=",")
feed_p <- read.csv(paste0(filepath, 'wasted_feed_Proteins.csv'), header=TRUE, sep=",")
nh4 <- read.csv(paste0(filepath, 'NH4_release.csv'), header=TRUE, sep=",")
weight <- read.csv(paste0(filepath, 'weight.csv'), header=TRUE, sep=",")
#extract columns
faeces_c <- faeces_c %>% select(X, V1, V2)
faeces_l <- faeces_l %>% select(V1, V2)
faeces_p <- faeces_p %>% select(V1, V2)
feed_c <- feed_c %>% select(V1, V2)
feed_l <- feed_l %>% select(V1, V2)
feed_p <- feed_p %>% select(V1, V2)
nh4 <- nh4 %>% select(V1, V2)
weight <- weight %>% select(V1, V2) %>% slice(1:nrow(faeces_c))
#compile columns to new dataframe
compiled <- cbind(faeces_c, faeces_l, faeces_p, feed_c, feed_l, feed_p, nh4, weight)
#rename columns
colnames(compiled) <- c("day", "faeces_c1", "faeces_c2", "faeces_l1", "faeces_l2", "faeces_p1", "faeces_p2",
"feed_c1", "feed_c2", "feed_l1", "feed_l2", "feed_p1", "feed_p2",
"nh4_1", "nh4_2", "weight_1", "weight_2")
#write csv
name <- paste0(rac_folder, 'output_compiled/site_', i, '_compiled.csv')
write.table(compiled, file = name, row.names=FALSE, col.names = TRUE, sep=",")}
for (i in sites){
compiler(rac_folder, site_folder, i)
compiler(rac_folder_2, site_folder_2, i)} #sebass
#function to combine farm site csv files to single csv
compiler_all <- function(rac_folder, site_folder, i){
#load csv files
id <- unlist(strsplit(i, "_"))[2]
harvest <-  read.csv(paste0(rac_folder, 'site_', id, site_folder, 'Days_to_commercial_size.csv'))
compiled <- read.csv(paste0(rac_folder, 'output_compiled/', i), header=TRUE, sep=",")
#extract columns
harvest <- harvest %>% select(3)
harvest <- harvest[[1]]
#sum rows by days of harvest
compiled <- compiled[1:harvest,] %>% select(2, 4, 6, 8, 10, 12)
compiled <- round(colSums(compiled))
compiled <- as.vector(c(id, compiled, harvest))}
#combine all
names <- c("site_ID", "faeces_c", "faeces_l", "faeces_p", "feed_c", "feed_l", "feed_p", "harvest day") #colnames
#bream
sites <- list.files(paste0(rac_folder, 'output_compiled/'), pattern = '.csv')
combined = list()
for (i in sites){combined[[i]] <- compiler_all(rac_folder, site_folder, i)}
combined_df<-data.frame(do.call(rbind, combined))
colnames(combined_df) <- names
#export dataframe as csv
write.table(combined_df, file = paste0('./combined_bream.csv'), row.names=FALSE, col.names = TRUE, sep=",")
#bass
sites <- list.files(paste0(rac_folder_2, 'output_compiled/'), pattern = '.csv')
combined = list()
for (i in sites){combined[[i]] <- compiler_all(rac_folder_2, site_folder_2, i)}
combined_df<-data.frame(do.call(rbind, combined))
colnames(combined_df) <- names
#export dataframe as csv
write.table(combined_df, file = paste0('./combined_seabass.csv'), row.names=FALSE, col.names = TRUE, sep=",")
library(RAC)
library(dplyr)
library(zoo) #index function
trace(Bream_pop_main,edit=T) #delete selector = "y"
farmsites <- read.csv('./master_inventory - Farm_Sites.csv', header=TRUE, sep=",")
sites <- as.vector(farmsites$farm_site)
#sites <- sites[1:5]
# sites <- sites[1:28]
# sites <- sites[29:56]
# sites <- sites[57:84]
# sites <- sites[85:112]
# sites <- sites[113:140]
# sites <- sites[141:168]
# sites <- sites[169:196]
# sites <- sites[197:209]
#load master files - LOCAL or AWS
rac_folder <- "/Users/Zack/0_seawarden/r_rac/rac_bream/"
# rac_folder <- "/Users/Administrator/Documents/GitHub/seawarden/r_rac/rac_bream/"
pre_sim <- 10
main_sim <- 100
start <- "1/4/2018" #apr 1, 2018
end_prep <- "19/12/2019"
end <- "15/12/2019"
#generate prep files for all sites
master_files <- paste0(rac_folder, 'master_files/master_RAC-bream - ')
sst_folder <- './sst/'
sst_list <- list.files(sst_folder, pattern = '.csv')
#prep files to generate feeding tables
feeding_prep <- read.csv(paste0(master_files, 'Feeding_Prep.csv'), header=TRUE, sep=",")
#files for both steps
population <- read.csv(paste0(master_files, 'Population.csv'), header=FALSE, sep=",", stringsAsFactors = FALSE)
parameters <- read.csv(paste0(master_files, 'Parameters.csv'), header=FALSE, sep=",", stringsAsFactors = FALSE)
management <- read.csv(paste0(master_files, 'Management.csv'), header=FALSE, sep=",")
food <- read.csv(paste0(master_files, 'Food_Characterization.csv'), header=FALSE, sep=",")
# #create folder for each site, #add SST data
for (i in sites){
#create a folder for each site
site_folder <- paste0(rac_folder, 'site_', i, '/')
dir.create(site_folder)
#create RAC folders for each site
Bream_pop_skeleton(site_folder)
#add SST data
orglocation <- paste0(sst_folder, i, '_sst.csv')
newlocation <- paste0(site_folder, 'Bream_population/Inputs/Forcings/')
file.copy(from=orglocation, to=newlocation, overwrite = TRUE, recursive = FALSE, copy.mode = TRUE)
file.remove(paste0(newlocation, 'Water_temperature.csv'))
file.rename(paste0(newlocation, i, '_sst.csv'), paste0(newlocation, 'Water_temperature.csv'))}
#load prep files for each site
#generate Population.csv for each site
for (i in index(sites)){
column <- i + 4
export <- population %>% select(1, 2, column, 3, 4)
export[9, 3] = pre_sim
site <- (population %>% select(column))[1,]
output <- paste0(rac_folder, 'site_', site, '/Bream_population/Inputs/Parameters/Population.csv')
write.table(export, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
library(RAC)
library(dplyr)
library(zoo) #index function
trace(Bream_pop_main,edit=T) #delete selector = "y"
farmsites <- read.csv('./master_inventory - Farm_Sites.csv', header=TRUE, sep=",")
sites <- as.vector(farmsites$farm_site)
#sites <- sites[1:5]
# sites <- sites[1:28]
# sites <- sites[29:56]
# sites <- sites[57:84]
# sites <- sites[85:112]
# sites <- sites[113:140]
# sites <- sites[141:168]
# sites <- sites[169:196]
# sites <- sites[197:209]
#load master files - LOCAL or AWS
rac_folder <- "/Users/Zack/0_seawarden/r_rac/rac_bream/"
# rac_folder <- "/Users/Administrator/Documents/GitHub/seawarden/r_rac/rac_bream/"
pre_sim <- 10
main_sim <- 100
start <- "1/4/2018" #apr 1, 2018
end_prep <- "19/12/2019"
end <- "15/12/2019"
#generate prep files for all sites
master_files <- paste0(rac_folder, 'master_files/master_RAC-bream - ')
sst_folder <- './sst/'
sst_list <- list.files(sst_folder, pattern = '.csv')
#prep files to generate feeding tables
feeding_prep <- read.csv(paste0(master_files, 'Feeding_Prep.csv'), header=TRUE, sep=",")
#files for both steps
population <- read.csv(paste0(master_files, 'Population.csv'), header=FALSE, sep=",", stringsAsFactors = FALSE)
parameters <- read.csv(paste0(master_files, 'Parameters.csv'), header=FALSE, sep=",", stringsAsFactors = FALSE)
management <- read.csv(paste0(master_files, 'Management.csv'), header=FALSE, sep=",")
food <- read.csv(paste0(master_files, 'Food_Characterization.csv'), header=FALSE, sep=",")
# #create folder for each site, #add SST data
for (i in sites){
#create a folder for each site
site_folder <- paste0(rac_folder, 'site_', i, '/')
dir.create(site_folder)
#create RAC folders for each site
Bream_pop_skeleton(site_folder)
#add SST data
orglocation <- paste0(sst_folder, i, '_sst.csv')
newlocation <- paste0(site_folder, 'Bream_population/Inputs/Forcings/')
file.copy(from=orglocation, to=newlocation, overwrite = TRUE, recursive = FALSE, copy.mode = TRUE)
file.remove(paste0(newlocation, 'Water_temperature.csv'))
file.rename(paste0(newlocation, i, '_sst.csv'), paste0(newlocation, 'Water_temperature.csv'))}
#load prep files for each site
#generate Population.csv for each site
for (i in index(sites)){
column <- i + 4
export <- population %>% select(1, 2, column, 3, 4)
export[9, 3] = pre_sim
site <- (population %>% select(column))[1,]
output <- paste0(rac_folder, 'site_', site, '/Bream_population/Inputs/Parameters/Population.csv')
write.table(export, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
#generate Parameters.csv for each site
for (i in sites){
export <- parameters %>% select(1, 2, 5, 3, 4) #5 prep parameters
export[23, 3] = start
export[24, 3] = end_prep
output <- paste0(rac_folder, 'site_', i, '/Bream_population/Inputs/Parameters/Parameters.csv')
write.table(export, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
#generate Feeding.csv for each site
for (i in sites){
output <- paste0(rac_folder, 'site_', i, '/Bream_population/Inputs/Forcings/Feeding.csv')
write.table(feeding_prep, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
#generate Management.csv for each site
for (i in sites){
export <- management %>% select(1, 2, 3)
output <- paste0(rac_folder, 'site_', i, '/Bream_population/Inputs/Population_management/Management.csv')
write.table(export, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
#generate Food_Characterization.csv for each site
for (i in sites){
export <- food %>% select(2, 1)
export <- export[-1,] #drop header
output <- paste0(rac_folder, 'site_', i, '/Bream_population/Inputs/Forcings/Food_Characterization.csv')
write.table(export, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
#first model run to generate feeding tables
for (i in sites){
userpath <- paste0(rac_folder, "site_", i)
setwd(userpath) #working directory
forcings <- Bream_pop_dataloader(userpath) #load environmental variables
output <- Bream_pop_main(userpath, forcings)} #run growth model
library(RAC)
library(dplyr)
library(zoo) #index function
trace(Bream_pop_main,edit=T) #delete selector = "y"
farmsites <- read.csv('./master_inventory - Farm_Sites.csv', header=TRUE, sep=",")
sites <- as.vector(farmsites$farm_site)
#sites <- sites[1:5]
# sites <- sites[1:28]
# sites <- sites[29:56]
# sites <- sites[57:84]
# sites <- sites[85:112]
# sites <- sites[113:140]
# sites <- sites[141:168]
# sites <- sites[169:196]
# sites <- sites[197:209]
#load master files - LOCAL or AWS
rac_folder <- "/Users/Zack/0_seawarden/r_rac/rac_bream/"
# rac_folder <- "/Users/Administrator/Documents/GitHub/seawarden/r_rac/rac_bream/"
pre_sim <- 10
main_sim <- 100
start <- "1/4/2018" #apr 1, 2018
end_prep <- "19/12/2019"
end <- "15/12/2019"
#generate prep files for all sites
master_files <- paste0(rac_folder, 'master_files/master_RAC-bream - ')
sst_folder <- './sst/'
sst_list <- list.files(sst_folder, pattern = '.csv')
#prep files to generate feeding tables
feeding_prep <- read.csv(paste0(master_files, 'Feeding_Prep.csv'), header=TRUE, sep=",")
#files for both steps
population <- read.csv(paste0(master_files, 'Population.csv'), header=FALSE, sep=",", stringsAsFactors = FALSE)
parameters <- read.csv(paste0(master_files, 'Parameters.csv'), header=FALSE, sep=",", stringsAsFactors = FALSE)
management <- read.csv(paste0(master_files, 'Management.csv'), header=FALSE, sep=",")
food <- read.csv(paste0(master_files, 'Food_Characterization.csv'), header=FALSE, sep=",")
# #create folder for each site, #add SST data
for (i in sites){
#create a folder for each site
site_folder <- paste0(rac_folder, 'site_', i, '/')
dir.create(site_folder)
#create RAC folders for each site
Bream_pop_skeleton(site_folder)
#add SST data
orglocation <- paste0(sst_folder, i, '_sst.csv')
newlocation <- paste0(site_folder, 'Bream_population/Inputs/Forcings/')
file.copy(from=orglocation, to=newlocation, overwrite = TRUE, recursive = FALSE, copy.mode = TRUE)
file.remove(paste0(newlocation, 'Water_temperature.csv'))
file.rename(paste0(newlocation, i, '_sst.csv'), paste0(newlocation, 'Water_temperature.csv'))}
#load prep files for each site
#generate Population.csv for each site
for (i in index(sites)){
column <- i + 4
export <- population %>% select(1, 2, column, 3, 4)
export[9, 3] = pre_sim
site <- (population %>% select(column))[1,]
output <- paste0(rac_folder, 'site_', site, '/Bream_population/Inputs/Parameters/Population.csv')
write.table(export, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
library(RAC)
library(dplyr)
library(zoo) #index function
trace(Bream_pop_main,edit=T) #delete selector = "y"
farmsites <- read.csv('./master_inventory - Farm_Sites.csv', header=TRUE, sep=",")
sites <- as.vector(farmsites$farm_site)
#sites <- sites[1:5]
# sites <- sites[1:28]
# sites <- sites[29:56]
# sites <- sites[57:84]
# sites <- sites[85:112]
# sites <- sites[113:140]
# sites <- sites[141:168]
# sites <- sites[169:196]
# sites <- sites[197:209]
#load master files - LOCAL or AWS
rac_folder <- "/Users/Zack/0_seawarden/r_rac/rac_bream/"
# rac_folder <- "/Users/Administrator/Documents/GitHub/seawarden/r_rac/rac_bream/"
pre_sim <- 10
main_sim <- 100
start <- "1/4/2018" #apr 1, 2018
end_prep <- "19/12/2019"
end <- "15/12/2019"
#generate prep files for all sites
master_files <- paste0(rac_folder, 'master_files/master_RAC-bream - ')
sst_folder <- './sst/'
sst_list <- list.files(sst_folder, pattern = '.csv')
#prep files to generate feeding tables
feeding_prep <- read.csv(paste0(master_files, 'Feeding_Prep.csv'), header=TRUE, sep=",")
#files for both steps
population <- read.csv(paste0(master_files, 'Population.csv'), header=FALSE, sep=",", stringsAsFactors = FALSE)
parameters <- read.csv(paste0(master_files, 'Parameters.csv'), header=FALSE, sep=",", stringsAsFactors = FALSE)
management <- read.csv(paste0(master_files, 'Management.csv'), header=FALSE, sep=",")
food <- read.csv(paste0(master_files, 'Food_Characterization.csv'), header=FALSE, sep=",")
# #create folder for each site, #add SST data
for (i in sites){
#create a folder for each site
site_folder <- paste0(rac_folder, 'site_', i, '/')
dir.create(site_folder)
#create RAC folders for each site
Bream_pop_skeleton(site_folder)
#add SST data
orglocation <- paste0(sst_folder, i, '_sst.csv')
newlocation <- paste0(site_folder, 'Bream_population/Inputs/Forcings/')
file.copy(from=orglocation, to=newlocation, overwrite = TRUE, recursive = FALSE, copy.mode = TRUE)
file.remove(paste0(newlocation, 'Water_temperature.csv'))
file.rename(paste0(newlocation, i, '_sst.csv'), paste0(newlocation, 'Water_temperature.csv'))}
#load prep files for each site
#generate Population.csv for each site
for (i in index(sites)){
column <- i + 4
export <- population %>% select(1, 2, column, 3, 4)
export[9, 3] = pre_sim
site <- (population %>% select(column))[1,]
output <- paste0(rac_folder, 'site_', site, '/Bream_population/Inputs/Parameters/Population.csv')
write.table(export, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
library(RAC)
library(dplyr)
library(zoo) #index function
trace(Bream_pop_main,edit=T) #delete selector = "y"
farmsites <- read.csv('./master_inventory - Farm_Sites.csv', header=TRUE, sep=",")
sites <- as.vector(farmsites$farm_site)
#sites <- sites[1:5]
# sites <- sites[1:28]
# sites <- sites[29:56]
# sites <- sites[57:84]
# sites <- sites[85:112]
# sites <- sites[113:140]
# sites <- sites[141:168]
# sites <- sites[169:196]
# sites <- sites[197:209]
#load master files - LOCAL or AWS
rac_folder <- "/Users/Zack/0_seawarden/r_rac/rac_bream/"
# rac_folder <- "/Users/Administrator/Documents/GitHub/seawarden/r_rac/rac_bream/"
pre_sim <- 10
main_sim <- 100
start <- "1/4/2018" #apr 1, 2018
end_prep <- "19/12/2019"
end <- "15/12/2019"
#generate prep files for all sites
master_files <- paste0(rac_folder, 'master_files/master_RAC-bream - ')
sst_folder <- './sst/'
sst_list <- list.files(sst_folder, pattern = '.csv')
#prep files to generate feeding tables
feeding_prep <- read.csv(paste0(master_files, 'Feeding_Prep.csv'), header=TRUE, sep=",")
#files for both steps
population <- read.csv(paste0(master_files, 'Population.csv'), header=FALSE, sep=",", stringsAsFactors = FALSE)
parameters <- read.csv(paste0(master_files, 'Parameters.csv'), header=FALSE, sep=",", stringsAsFactors = FALSE)
management <- read.csv(paste0(master_files, 'Management.csv'), header=FALSE, sep=",")
food <- read.csv(paste0(master_files, 'Food_Characterization.csv'), header=FALSE, sep=",")
# #create folder for each site, #add SST data
# for (i in sites){
#
#   #create a folder for each site
#   site_folder <- paste0(rac_folder, 'site_', i, '/')
#   dir.create(site_folder)
#
#   #create RAC folders for each site
#   Bream_pop_skeleton(site_folder)
#
#   #add SST data
#   orglocation <- paste0(sst_folder, i, '_sst.csv')
#   newlocation <- paste0(site_folder, 'Bream_population/Inputs/Forcings/')
#   file.copy(from=orglocation, to=newlocation, overwrite = TRUE, recursive = FALSE, copy.mode = TRUE)
#   file.remove(paste0(newlocation, 'Water_temperature.csv'))
#   file.rename(paste0(newlocation, i, '_sst.csv'), paste0(newlocation, 'Water_temperature.csv'))}
#load prep files for each site
#generate Population.csv for each site
for (i in index(sites)){
column <- i + 4
export <- population %>% select(1, 2, column, 3, 4)
export[9, 3] = pre_sim
site <- (population %>% select(column))[1,]
output <- paste0(rac_folder, 'site_', site, '/Bream_population/Inputs/Parameters/Population.csv')
write.table(export, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
#generate Parameters.csv for each site
for (i in sites){
export <- parameters %>% select(1, 2, 5, 3, 4) #5 prep parameters
export[23, 3] = start
export[24, 3] = end_prep
output <- paste0(rac_folder, 'site_', i, '/Bream_population/Inputs/Parameters/Parameters.csv')
write.table(export, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
#generate Feeding.csv for each site
for (i in sites){
output <- paste0(rac_folder, 'site_', i, '/Bream_population/Inputs/Forcings/Feeding.csv')
write.table(feeding_prep, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
#generate Management.csv for each site
for (i in sites){
export <- management %>% select(1, 2, 3)
output <- paste0(rac_folder, 'site_', i, '/Bream_population/Inputs/Population_management/Management.csv')
write.table(export, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
#generate Food_Characterization.csv for each site
for (i in sites){
export <- food %>% select(2, 1)
export <- export[-1,] #drop header
output <- paste0(rac_folder, 'site_', i, '/Bream_population/Inputs/Forcings/Food_Characterization.csv')
write.table(export, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
#first model run to generate feeding tables
for (i in sites){
userpath <- paste0(rac_folder, "site_", i)
setwd(userpath) #working directory
forcings <- Bream_pop_dataloader(userpath) #load environmental variables
output <- Bream_pop_main(userpath, forcings)} #run growth model
#generate final feeding tables
feeding <- function(rac_folder, i){
site_folder <- paste0('site_', i, '/Bream_population/Outputs/Out_csv/')
ingestion <- read.csv(paste0(rac_folder, site_folder, 'actual_ingestion.csv'), header=TRUE, sep=",")
ingestion <- ingestion %>% select(V1)
#ingestion$V1 <- ingestion$V1 * 1.3 #adjust
date <- feeding_prep %>% select(date)
#date <- date$date[1:nrow(ingestion)]
date <- date$date[92:718]
compiled <- cbind(date, ingestion)
name <- paste0(rac_folder, 'feeding_files/site_', i, '_feeding.csv')
write.table(compiled, file = name, row.names=FALSE, col.names = TRUE, sep=",")}
for (i in sites){feeding(rac_folder, i)}
#load data for final model run
#generate Population.csv for each site
for (i in index(sites)){
column <- i + 4
export <- population %>% select(1, 2, column, 3, 4)
export[9, 3] = main_sim
site <- (population %>% select(column))[1,]
output <- paste0(rac_folder, 'site_', site, '/Bream_population/Inputs/Parameters/Population.csv')
write.table(export, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
#generate Parameters.csv for each site
for (i in sites){
export <- parameters %>% select(1, 2, 6, 3, 4) #6 final parameters
export[23, 3] = start
export[24, 3] = end
output <- paste0(rac_folder, 'site_', i, '/Bream_population/Inputs/Parameters/Parameters.csv')
write.table(export, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
#generate Feeding.csv for each site
for (i in sites){
feed <- read.csv(paste0(rac_folder, 'feeding_files/site_', i, '_feeding.csv'))
output <- paste0(rac_folder, 'site_', i, '/Bream_population/Inputs/Forcings/Feeding.csv')
write.table(feed, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
for (i in sites){
userpath <- paste0(rac_folder, "site_", i)
setwd(userpath) #working directory
forcings <- Bream_pop_dataloader(userpath) #load environmental variables
output <- Bream_pop_main(userpath, forcings)} #run growth model
# library(foreach)
# library(doParallel)
# library(parallel)
#
# numCores <- detectCores()
# cl <- makeCluster(numCores)
# registerDoParallel(cl)
#
# inputs <- 1:10
# processInput <- function(i) {i * i}
# results <- foreach(i=inputs) %dopar% {processInput(i)}
# library(foreach)
# library(doParallel)
#
# rac_tool <- function(rac_folder, i){
#   userpath <- paste0(rac_folder, "site_", i)
#   setwd(userpath)
#   forcings <- Bream_pop_dataloader(userpath)
#   output <- Bream_pop_main(userpath, forcings)}
#
# #select numbrer of cores
# myCluster <- makeCluster(3, type = "PSOCK")
#
# #activate clusters
# registerDoParallel(myCluster)
#
# #parallel process
# foreach(i = sites, .packages = 'RAC') %dopar% rac_tool(rac_folder, i)
#
# #deactivate clusters
# stopCluster(myCluster)
