feed_c <- read.csv(paste0(filepath, 'wasted_feed_Carbohydrates.csv'), header=TRUE, sep=",")
feed_l <- read.csv(paste0(filepath, 'wasted_feed_Lipids.csv'), header=TRUE, sep=",")
feed_p <- read.csv(paste0(filepath, 'wasted_feed_Proteins.csv'), header=TRUE, sep=",")
nh4 <- read.csv(paste0(filepath, 'NH4_release.csv'), header=TRUE, sep=",")
weight <- read.csv(paste0(filepath, 'weight.csv'), header=TRUE, sep=",")
#extract columns
faeces_c <- faeces_c %>% select(X, V1, V2)
faeces_l <- faeces_l %>% select(V1, V2)
faeces_p <- faeces_p %>% select(V1, V2)
feed_c <- feed_c %>% select(V1, V2)
feed_l <- feed_l %>% select(V1, V2)
feed_p <- feed_p %>% select(V1, V2)
nh4 <- nh4 %>% select(V1, V2)
weight <- weight %>% select(V1, V2)
weight1 <- weight$V1[1:543]
weight2 <- weight$V2[1:543]
#compile columns to new dataframe
compiled <- cbind(faeces_c, faeces_l, faeces_p, feed_c, feed_l, feed_p, nh4, weight1, weight2)
#rename columns
colnames(compiled) <- c("day",
"faeces_c1", "faeces_c2", "faeces_l1", "faeces_l2", "faeces_p1", "faeces_p2",
"feed_c1", "feed_c2", "feed_l1", "feed_l2", "feed_p1", "feed_p2",
"nh4_1", "nh4_2", "weight_1", "weight_2")
#write csv
name <- paste0(rac_folder, 'output_files/site_', i, '_compiled.csv')
write.table(compiled, file = name, row.names=FALSE, col.names = TRUE, sep=",")}
sites <- list(23, 71, 92, 165, 172, 219)
rac_folder <- '/Users/Zack/0_seawarden/r_rac/rac_seabass/'
site_folder <- '/Bass_population/Outputs/Out_csv/'
for (i in sites){
compiler(rac_folder, site_folder, i)}
rac_folder <- '/Users/Zack/0_seawarden/r_rac/rac_bream/'
site_folder <- '/Bream_population/Outputs/Out_csv/'
for (i in sites){
compiler(rac_bream, site_folder, i)}
library(dplyr)
#combine RAC predictions for each farmsite in to one csv file
compiler <- function(rac_folder, site_folder, i){
filepath <- paste0(rac_folder, 'site_', i, site_folder)
#load csv files
faeces_c <- read.csv(paste0(filepath, 'faeces_production_Carbohydrates.csv'), header=TRUE, sep=",")
faeces_l <- read.csv(paste0(filepath, 'faeces_production_Lipids.csv'), header=TRUE, sep=",")
faeces_p <- read.csv(paste0(filepath, 'faeces_production_Proteins.csv'), header=TRUE, sep=",")
feed_c <- read.csv(paste0(filepath, 'wasted_feed_Carbohydrates.csv'), header=TRUE, sep=",")
feed_l <- read.csv(paste0(filepath, 'wasted_feed_Lipids.csv'), header=TRUE, sep=",")
feed_p <- read.csv(paste0(filepath, 'wasted_feed_Proteins.csv'), header=TRUE, sep=",")
nh4 <- read.csv(paste0(filepath, 'NH4_release.csv'), header=TRUE, sep=",")
weight <- read.csv(paste0(filepath, 'weight.csv'), header=TRUE, sep=",")
#extract columns
faeces_c <- faeces_c %>% select(X, V1, V2)
faeces_l <- faeces_l %>% select(V1, V2)
faeces_p <- faeces_p %>% select(V1, V2)
feed_c <- feed_c %>% select(V1, V2)
feed_l <- feed_l %>% select(V1, V2)
feed_p <- feed_p %>% select(V1, V2)
nh4 <- nh4 %>% select(V1, V2)
weight <- weight %>% select(V1, V2)
weight1 <- weight %>% slice(1:543)
# weight$V1[1:543]
# weight2 <- weight$V2[1:543]
#compile columns to new dataframe
compiled <- cbind(faeces_c, faeces_l, faeces_p, feed_c, feed_l, feed_p, nh4, weight1, weight2)
#rename columns
colnames(compiled) <- c("day", "faeces_c1", "faeces_c2", "faeces_l1", "faeces_l2", "faeces_p1", "faeces_p2",
"feed_c1", "feed_c2", "feed_l1", "feed_l2", "feed_p1", "feed_p2",
"nh4_1", "nh4_2", "weight_1", "weight_2")
#write csv
name <- paste0(rac_folder, 'output_files/site_', i, '_compiled.csv')
write.table(compiled, file = name, row.names=FALSE, col.names = TRUE, sep=",")}
sites <- list(23, 71, 92, 165, 172, 219)
rac_folder <- '/Users/Zack/0_seawarden/r_rac/rac_seabass/'
site_folder <- '/Bass_population/Outputs/Out_csv/'
for (i in sites){
compiler(rac_folder, site_folder, i)}
library(dplyr)
#combine RAC predictions for each farmsite in to one csv file
compiler <- function(rac_folder, site_folder, i){
filepath <- paste0(rac_folder, 'site_', i, site_folder)
#load csv files
faeces_c <- read.csv(paste0(filepath, 'faeces_production_Carbohydrates.csv'), header=TRUE, sep=",")
faeces_l <- read.csv(paste0(filepath, 'faeces_production_Lipids.csv'), header=TRUE, sep=",")
faeces_p <- read.csv(paste0(filepath, 'faeces_production_Proteins.csv'), header=TRUE, sep=",")
feed_c <- read.csv(paste0(filepath, 'wasted_feed_Carbohydrates.csv'), header=TRUE, sep=",")
feed_l <- read.csv(paste0(filepath, 'wasted_feed_Lipids.csv'), header=TRUE, sep=",")
feed_p <- read.csv(paste0(filepath, 'wasted_feed_Proteins.csv'), header=TRUE, sep=",")
nh4 <- read.csv(paste0(filepath, 'NH4_release.csv'), header=TRUE, sep=",")
weight <- read.csv(paste0(filepath, 'weight.csv'), header=TRUE, sep=",")
#extract columns
faeces_c <- faeces_c %>% select(X, V1, V2)
faeces_l <- faeces_l %>% select(V1, V2)
faeces_p <- faeces_p %>% select(V1, V2)
feed_c <- feed_c %>% select(V1, V2)
feed_l <- feed_l %>% select(V1, V2)
feed_p <- feed_p %>% select(V1, V2)
nh4 <- nh4 %>% select(V1, V2)
weight <- weight %>% select(V1, V2)
weight <- weight %>% slice(1:543)
# weight$V1[1:543]
# weight2 <- weight$V2[1:543]
#compile columns to new dataframe
compiled <- cbind(faeces_c, faeces_l, faeces_p, feed_c, feed_l, feed_p, nh4, weight)#1, weight2)
#rename columns
colnames(compiled) <- c("day", "faeces_c1", "faeces_c2", "faeces_l1", "faeces_l2", "faeces_p1", "faeces_p2",
"feed_c1", "feed_c2", "feed_l1", "feed_l2", "feed_p1", "feed_p2",
"nh4_1", "nh4_2", "weight_1", "weight_2")
#write csv
name <- paste0(rac_folder, 'output_files/site_', i, '_compiled.csv')
write.table(compiled, file = name, row.names=FALSE, col.names = TRUE, sep=",")}
sites <- list(23, 71, 92, 165, 172, 219)
rac_folder <- '/Users/Zack/0_seawarden/r_rac/rac_seabass/'
site_folder <- '/Bass_population/Outputs/Out_csv/'
for (i in sites){
compiler(rac_folder, site_folder, i)}
rac_folder <- '/Users/Zack/0_seawarden/r_rac/rac_bream/'
site_folder <- '/Bream_population/Outputs/Out_csv/'
for (i in sites){
compiler(rac_bream, site_folder, i)}
library(dplyr)
#combine RAC predictions for each farmsite in to one csv file
compiler <- function(rac_folder, site_folder, i){
filepath <- paste0(rac_folder, 'site_', i, site_folder)
#load csv files
faeces_c <- read.csv(paste0(filepath, 'faeces_production_Carbohydrates.csv'), header=TRUE, sep=",")
faeces_l <- read.csv(paste0(filepath, 'faeces_production_Lipids.csv'), header=TRUE, sep=",")
faeces_p <- read.csv(paste0(filepath, 'faeces_production_Proteins.csv'), header=TRUE, sep=",")
feed_c <- read.csv(paste0(filepath, 'wasted_feed_Carbohydrates.csv'), header=TRUE, sep=",")
feed_l <- read.csv(paste0(filepath, 'wasted_feed_Lipids.csv'), header=TRUE, sep=",")
feed_p <- read.csv(paste0(filepath, 'wasted_feed_Proteins.csv'), header=TRUE, sep=",")
nh4 <- read.csv(paste0(filepath, 'NH4_release.csv'), header=TRUE, sep=",")
weight <- read.csv(paste0(filepath, 'weight.csv'), header=TRUE, sep=",")
#extract columns
faeces_c <- faeces_c %>% select(X, V1, V2)
faeces_l <- faeces_l %>% select(V1, V2)
faeces_p <- faeces_p %>% select(V1, V2)
feed_c <- feed_c %>% select(V1, V2)
feed_l <- feed_l %>% select(V1, V2)
feed_p <- feed_p %>% select(V1, V2)
nh4 <- nh4 %>% select(V1, V2)
weight <- weight %>% select(V1, V2) %>% slice(1:543)
#  weight <- weight %>% slice(1:543)
#compile columns to new dataframe
compiled <- cbind(faeces_c, faeces_l, faeces_p, feed_c, feed_l, feed_p, nh4, weight)
#rename columns
colnames(compiled) <- c("day", "faeces_c1", "faeces_c2", "faeces_l1", "faeces_l2", "faeces_p1", "faeces_p2",
"feed_c1", "feed_c2", "feed_l1", "feed_l2", "feed_p1", "feed_p2",
"nh4_1", "nh4_2", "weight_1", "weight_2")
#write csv
name <- paste0(rac_folder, 'output_files/site_', i, '_compiled.csv')
write.table(compiled, file = name, row.names=FALSE, col.names = TRUE, sep=",")}
sites <- list(23, 71, 92, 165, 172, 219)
rac_folder <- '/Users/Zack/0_seawarden/r_rac/rac_seabass/'
site_folder <- '/Bass_population/Outputs/Out_csv/'
for (i in sites){
compiler(rac_folder, site_folder, i)}
rac_folder <- '/Users/Zack/0_seawarden/r_rac/rac_bream/'
site_folder <- '/Bream_population/Outputs/Out_csv/'
for (i in sites){
compiler(rac_bream, site_folder, i)}
library(dplyr)
#combine RAC predictions for each farmsite in to one csv file
compiler <- function(rac_folder, site_folder, i){
filepath <- paste0(rac_folder, 'site_', i, site_folder)
#load csv files
faeces_c <- read.csv(paste0(filepath, 'faeces_production_Carbohydrates.csv'), header=TRUE, sep=",")
faeces_l <- read.csv(paste0(filepath, 'faeces_production_Lipids.csv'), header=TRUE, sep=",")
faeces_p <- read.csv(paste0(filepath, 'faeces_production_Proteins.csv'), header=TRUE, sep=",")
feed_c <- read.csv(paste0(filepath, 'wasted_feed_Carbohydrates.csv'), header=TRUE, sep=",")
feed_l <- read.csv(paste0(filepath, 'wasted_feed_Lipids.csv'), header=TRUE, sep=",")
feed_p <- read.csv(paste0(filepath, 'wasted_feed_Proteins.csv'), header=TRUE, sep=",")
nh4 <- read.csv(paste0(filepath, 'NH4_release.csv'), header=TRUE, sep=",")
weight <- read.csv(paste0(filepath, 'weight.csv'), header=TRUE, sep=",")
#extract columns
faeces_c <- faeces_c %>% select(X, V1, V2)
faeces_l <- faeces_l %>% select(V1, V2)
faeces_p <- faeces_p %>% select(V1, V2)
feed_c <- feed_c %>% select(V1, V2)
feed_l <- feed_l %>% select(V1, V2)
feed_p <- feed_p %>% select(V1, V2)
nh4 <- nh4 %>% select(V1, V2)
weight <- weight %>% select(V1, V2) %>% slice(1:543)
#  weight <- weight %>% slice(1:543)
#compile columns to new dataframe
compiled <- cbind(faeces_c, faeces_l, faeces_p, feed_c, feed_l, feed_p, nh4, weight)
#rename columns
colnames(compiled) <- c("day", "faeces_c1", "faeces_c2", "faeces_l1", "faeces_l2", "faeces_p1", "faeces_p2",
"feed_c1", "feed_c2", "feed_l1", "feed_l2", "feed_p1", "feed_p2",
"nh4_1", "nh4_2", "weight_1", "weight_2")
#write csv
name <- paste0(rac_folder, 'output_files/site_', i, '_compiled.csv')
write.table(compiled, file = name, row.names=FALSE, col.names = TRUE, sep=",")}
sites <- list(23, 71, 92, 165, 172, 219)
rac_folder <- '/Users/Zack/0_seawarden/r_rac/rac_seabass/'
site_folder <- '/Bass_population/Outputs/Out_csv/'
for (i in sites){
compiler(rac_folder, site_folder, i)}
rac_folder <- '/Users/Zack/0_seawarden/r_rac/rac_bream/'
site_folder <- '/Bream_population/Outputs/Out_csv/'
for (i in sites){
compiler(rac_bream, site_folder, i)}
library(dplyr)
#combine RAC predictions for each farmsite in to one csv file
compiler <- function(rac_folder, site_folder, i){
filepath <- paste0(rac_folder, 'site_', i, site_folder)
#load csv files
faeces_c <- read.csv(paste0(filepath, 'faeces_production_Carbohydrates.csv'), header=TRUE, sep=",")
faeces_l <- read.csv(paste0(filepath, 'faeces_production_Lipids.csv'), header=TRUE, sep=",")
faeces_p <- read.csv(paste0(filepath, 'faeces_production_Proteins.csv'), header=TRUE, sep=",")
feed_c <- read.csv(paste0(filepath, 'wasted_feed_Carbohydrates.csv'), header=TRUE, sep=",")
feed_l <- read.csv(paste0(filepath, 'wasted_feed_Lipids.csv'), header=TRUE, sep=",")
feed_p <- read.csv(paste0(filepath, 'wasted_feed_Proteins.csv'), header=TRUE, sep=",")
nh4 <- read.csv(paste0(filepath, 'NH4_release.csv'), header=TRUE, sep=",")
weight <- read.csv(paste0(filepath, 'weight.csv'), header=TRUE, sep=",")
#extract columns
faeces_c <- faeces_c %>% select(X, V1, V2)
faeces_l <- faeces_l %>% select(V1, V2)
faeces_p <- faeces_p %>% select(V1, V2)
feed_c <- feed_c %>% select(V1, V2)
feed_l <- feed_l %>% select(V1, V2)
feed_p <- feed_p %>% select(V1, V2)
nh4 <- nh4 %>% select(V1, V2)
weight <- weight %>% select(V1, V2) %>% slice(1:543)
#compile columns to new dataframe
compiled <- cbind(faeces_c, faeces_l, faeces_p, feed_c, feed_l, feed_p, nh4, weight)
#rename columns
colnames(compiled) <- c("day", "faeces_c1", "faeces_c2", "faeces_l1", "faeces_l2", "faeces_p1", "faeces_p2",
"feed_c1", "feed_c2", "feed_l1", "feed_l2", "feed_p1", "feed_p2",
"nh4_1", "nh4_2", "weight_1", "weight_2")
#write csv
name <- paste0(rac_folder, 'output_files/site_', i, '_compiled.csv')
write.table(compiled, file = name, row.names=FALSE, col.names = TRUE, sep=",")}
sites <- list(23, 71, 92, 165, 172, 219)
rac_bream
library(dplyr)
#combine RAC predictions for each farmsite in to one csv file
compiler <- function(rac_folder, site_folder, i){
filepath <- paste0(rac_folder, 'site_', i, site_folder)
#load csv files
faeces_c <- read.csv(paste0(filepath, 'faeces_production_Carbohydrates.csv'), header=TRUE, sep=",")
faeces_l <- read.csv(paste0(filepath, 'faeces_production_Lipids.csv'), header=TRUE, sep=",")
faeces_p <- read.csv(paste0(filepath, 'faeces_production_Proteins.csv'), header=TRUE, sep=",")
feed_c <- read.csv(paste0(filepath, 'wasted_feed_Carbohydrates.csv'), header=TRUE, sep=",")
feed_l <- read.csv(paste0(filepath, 'wasted_feed_Lipids.csv'), header=TRUE, sep=",")
feed_p <- read.csv(paste0(filepath, 'wasted_feed_Proteins.csv'), header=TRUE, sep=",")
nh4 <- read.csv(paste0(filepath, 'NH4_release.csv'), header=TRUE, sep=",")
weight <- read.csv(paste0(filepath, 'weight.csv'), header=TRUE, sep=",")
#extract columns
faeces_c <- faeces_c %>% select(X, V1, V2)
faeces_l <- faeces_l %>% select(V1, V2)
faeces_p <- faeces_p %>% select(V1, V2)
feed_c <- feed_c %>% select(V1, V2)
feed_l <- feed_l %>% select(V1, V2)
feed_p <- feed_p %>% select(V1, V2)
nh4 <- nh4 %>% select(V1, V2)
weight <- weight %>% select(V1, V2) %>% slice(1:543)
#compile columns to new dataframe
compiled <- cbind(faeces_c, faeces_l, faeces_p, feed_c, feed_l, feed_p, nh4, weight)
#rename columns
colnames(compiled) <- c("day", "faeces_c1", "faeces_c2", "faeces_l1", "faeces_l2", "faeces_p1", "faeces_p2",
"feed_c1", "feed_c2", "feed_l1", "feed_l2", "feed_p1", "feed_p2",
"nh4_1", "nh4_2", "weight_1", "weight_2")
#write csv
name <- paste0(rac_folder, 'output_files/site_', i, '_compiled.csv')
write.table(compiled, file = name, row.names=FALSE, col.names = TRUE, sep=",")}
sites <- list(23, 71, 92, 165, 172, 219)
rac_folder <- '/Users/Zack/0_seawarden/r_rac/rac_seabass/'
site_folder <- '/Bass_population/Outputs/Out_csv/'
for (i in sites){
compiler(rac_folder, site_folder, i)}
rac_folder <- '/Users/Zack/0_seawarden/r_rac/rac_bream/'
site_folder <- '/Bream_population/Outputs/Out_csv/'
for (i in sites){
compiler(rac_folder, site_folder, i)}
library(RAC)
library(dplyr)
#command + shift + c
#load sst files
sst_folder <- '/Users/Zack/0_thesis_sst/ghrsst_csv_test/'
sst_list <- list.files(sst_folder, pattern = '.csv')
#load master files
rac_folder <- "/Users/Zack/0_seawarden/r_rac/rac_bream/"
master_files <- paste0(rac_folder, 'master_files/master_RAC-bream - ')
#prep files to generate feeding tables
feeding_prep <- read.csv(paste0(master_files, 'Feeding_Prep.csv'), header=TRUE, sep=",")
population_prep <- read.csv(paste0(master_files, 'Population_Prep.csv'), header=FALSE, sep=",")
#files for final model run
population <- read.csv(paste0(master_files, 'Population.csv'), header=FALSE, sep=",")
parameters <- read.csv(paste0(master_files, 'Parameters.csv'), header=FALSE, sep=",")
#files for both steps
management <- read.csv(paste0(master_files, 'Management.csv'), header=FALSE, sep=",")
food <- read.csv(paste0(master_files, 'Food_Characterization.csv'), header=FALSE, sep=",")
sites <- list(23, 71, 92, 165, 172, 219) #study sites
#create folder for each site, #add SST data
for (i in sites){
#create a folder for each site
site_folder <- paste0(rac_folder, 'site_', i, '/')
dir.create(site_folder)
#create RAC folders for each site
Bream_pop_skeleton(site_folder)
#add SST data
orglocation <- paste0(sst_folder, i, '_sst.csv')
newlocation <- paste0(site_folder, 'Bream_population/Inputs/Forcings/')
file.copy(from=orglocation, to=newlocation, overwrite = TRUE, recursive = FALSE, copy.mode = TRUE)
file.remove(paste0(newlocation, 'Water_temperature.csv'))
file.rename(paste0(newlocation, i, '_sst.csv'), paste0(newlocation, 'Water_temperature.csv'))}
#load prep files for each site
#generate Population.csv for each site
for (i in sites){
for (j in 0:(length(sites)-1)){
column <- j + 5 #!
export <- population_prep %>% select(1, 2, column, 3, 4)}
output <- paste0(rac_folder, 'site_', i, '/Bream_population/Inputs/Parameters/Population.csv')
write.table(export, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
#generate Parameters.csv for each site
for (i in sites){
export <- parameters %>% select(1, 2, 5, 3, 4) #5 prep parameters
output <- paste0(rac_folder, 'site_', i, '/Bream_population/Inputs/Parameters/Parameters.csv')
write.table(export, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
#generate Feeding.csv for each site
for (i in sites){
output <- paste0(rac_folder, 'site_', i, '/Bream_population/Inputs/Forcings/Feeding.csv')
write.table(feeding_prep, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
#generate Management.csv for each site
for (i in sites){
export <- management %>% select(1, 2, 3)
output <- paste0(rac_folder, 'site_', i, '/Bream_population/Inputs/Population_management/Management.csv')
write.table(export, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
#generate Food_Characterization.csv for each site
for (i in sites){
export <- food %>% select(2, 1)
export <- export[-1,] #drop header
output <- paste0(rac_folder, 'site_', i, '/Bream_population/Inputs/Forcings/Food_Characterization.csv')
write.table(export, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
#first model run to generate feeding tables
trace(Bream_pop_main,edit=T) #delete selector = "y"
# for (i in sites){
#   userpath <- paste0(rac_folder, "site_", i)
#
#   setwd(userpath) #working directory
#
#   forcings <- Bream_pop_dataloader(userpath) #load environmental variables
#
#   output <- Bream_pop_main(userpath, forcings)} #run growth model
#parallel processing
#http://pablobarbera.com/ECPR-SC105/code/02-parallel-computing.html
#https://nceas.github.io/oss-lessons/parallel-computing-in-r/parallel-computing-in-r.html
#http://dept.stat.lsa.umich.edu/~jerrick/courses/stat701/notes/parallel.html
rac<- function(rac_folder, i){
library(RAC)
userpath <- paste0(rac_folder, "site_", i)
setwd(userpath) #working directory
forcings <- Bream_pop_dataloader(userpath) #load environmental variables
output <- Bream_pop_main(userpath, forcings)} #run growth model
library(foreach)
library(doParallel)
#select numbrer of cores
myCluster <- makeCluster(3, type = "PSOCK")
#activate clusters
registerDoParallel(myCluster)
#parallel process
foreach(i = sites) %dopar% rac(rac_folder, i)
#parallel processing
#http://pablobarbera.com/ECPR-SC105/code/02-parallel-computing.html
#https://nceas.github.io/oss-lessons/parallel-computing-in-r/parallel-computing-in-r.html
#http://dept.stat.lsa.umich.edu/~jerrick/courses/stat701/notes/parallel.html
rac<- function(rac_folder, i){
library(RAC)
userpath <- paste0(rac_folder, "site_", i)
setwd(userpath) #working directory
forcings <- Bream_pop_dataloader(userpath) #load environmental variables
output <- Bream_pop_main(userpath, forcings)} #run growth model
library(foreach)
library(doParallel)
#select numbrer of cores
myCluster <- makeCluster(3, type = "PSOCK")
#activate clusters
registerDoParallel(myCluster)
#parallel process
foreach(i = sites) %dopar% rac(rac_folder, i)
library(RAC)
library(dplyr)
#command + shift + c
#load sst files
sst_folder <- '/Users/Zack/0_thesis_sst/ghrsst_csv_test/'
sst_list <- list.files(sst_folder, pattern = '.csv')
#load master files
rac_folder <- "/Users/Zack/0_seawarden/r_rac/rac_bream/"
master_files <- paste0(rac_folder, 'master_files/master_RAC-bream - ')
#prep files to generate feeding tables
feeding_prep <- read.csv(paste0(master_files, 'Feeding_Prep.csv'), header=TRUE, sep=",")
population_prep <- read.csv(paste0(master_files, 'Population_Prep.csv'), header=FALSE, sep=",")
#files for final model run
population <- read.csv(paste0(master_files, 'Population.csv'), header=FALSE, sep=",")
parameters <- read.csv(paste0(master_files, 'Parameters.csv'), header=FALSE, sep=",")
#files for both steps
management <- read.csv(paste0(master_files, 'Management.csv'), header=FALSE, sep=",")
food <- read.csv(paste0(master_files, 'Food_Characterization.csv'), header=FALSE, sep=",")
sites <- list(23, 71, 92, 165, 172, 219) #study sites
#create folder for each site, #add SST data
for (i in sites){
#create a folder for each site
site_folder <- paste0(rac_folder, 'site_', i, '/')
dir.create(site_folder)
#create RAC folders for each site
Bream_pop_skeleton(site_folder)
#add SST data
orglocation <- paste0(sst_folder, i, '_sst.csv')
newlocation <- paste0(site_folder, 'Bream_population/Inputs/Forcings/')
file.copy(from=orglocation, to=newlocation, overwrite = TRUE, recursive = FALSE, copy.mode = TRUE)
file.remove(paste0(newlocation, 'Water_temperature.csv'))
file.rename(paste0(newlocation, i, '_sst.csv'), paste0(newlocation, 'Water_temperature.csv'))}
#load prep files for each site
#generate Population.csv for each site
for (i in sites){
for (j in 0:(length(sites)-1)){
column <- j + 5 #!
export <- population_prep %>% select(1, 2, column, 3, 4)}
output <- paste0(rac_folder, 'site_', i, '/Bream_population/Inputs/Parameters/Population.csv')
write.table(export, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
#generate Parameters.csv for each site
for (i in sites){
export <- parameters %>% select(1, 2, 5, 3, 4) #5 prep parameters
output <- paste0(rac_folder, 'site_', i, '/Bream_population/Inputs/Parameters/Parameters.csv')
write.table(export, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
#generate Feeding.csv for each site
for (i in sites){
output <- paste0(rac_folder, 'site_', i, '/Bream_population/Inputs/Forcings/Feeding.csv')
write.table(feeding_prep, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
#generate Management.csv for each site
for (i in sites){
export <- management %>% select(1, 2, 3)
output <- paste0(rac_folder, 'site_', i, '/Bream_population/Inputs/Population_management/Management.csv')
write.table(export, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
#generate Food_Characterization.csv for each site
for (i in sites){
export <- food %>% select(2, 1)
export <- export[-1,] #drop header
output <- paste0(rac_folder, 'site_', i, '/Bream_population/Inputs/Forcings/Food_Characterization.csv')
write.table(export, file = output, row.names=FALSE, col.names = FALSE, sep=",")}
#first model run to generate feeding tables
trace(Bream_pop_main,edit=T) #delete selector = "y"
# for (i in sites){
#   userpath <- paste0(rac_folder, "site_", i)
#
#   setwd(userpath) #working directory
#
#   forcings <- Bream_pop_dataloader(userpath) #load environmental variables
#
#   output <- Bream_pop_main(userpath, forcings)} #run growth model
#parallel processing
#http://pablobarbera.com/ECPR-SC105/code/02-parallel-computing.html
#https://nceas.github.io/oss-lessons/parallel-computing-in-r/parallel-computing-in-r.html
#http://dept.stat.lsa.umich.edu/~jerrick/courses/stat701/notes/parallel.html
rac<- function(rac_folder, i){
library(RAC)
userpath <- paste0(rac_folder, "site_", i)
setwd(userpath) #working directory
forcings <- Bream_pop_dataloader(userpath) #load environmental variables
output <- Bream_pop_main(userpath, forcings)} #run growth model
library(foreach)
library(doParallel)
#select numbrer of cores
myCluster <- makeCluster(3, type = "PSOCK")
#activate clusters
registerDoParallel(myCluster)
#parallel process
foreach(i = sites) %dopar% rac(rac_folder, i)
#parallel processing
#http://pablobarbera.com/ECPR-SC105/code/02-parallel-computing.html
#https://nceas.github.io/oss-lessons/parallel-computing-in-r/parallel-computing-in-r.html
#http://dept.stat.lsa.umich.edu/~jerrick/courses/stat701/notes/parallel.html
rac<- function(rac_folder, i){
library(RAC)
userpath <- paste0(rac_folder, "site_", i)
setwd(userpath) #working directory
forcings <- Bream_pop_dataloader(userpath) #load environmental variables
output <- Bream_pop_main(userpath, forcings)} #run growth model
library(foreach)
library(doParallel)
#select numbrer of cores
myCluster <- makeCluster(3, type = "PSOCK")
#activate clusters
registerDoParallel(myCluster)
#parallel process
foreach(i = sites) %dopar% rac(rac_folder, i)
#first model run to generate feeding tables
trace(Bream_pop_main,edit=T) #delete selector = "y"
for (i in sites){
userpath <- paste0(rac_folder, "site_", i)
setwd(userpath) #working directory
forcings <- Bream_pop_dataloader(userpath) #load environmental variables
output <- Bream_pop_main(userpath, forcings)} #run growth model
sites
userpath
#parallel processing
#http://pablobarbera.com/ECPR-SC105/code/02-parallel-computing.html
#https://nceas.github.io/oss-lessons/parallel-computing-in-r/parallel-computing-in-r.html
#http://dept.stat.lsa.umich.edu/~jerrick/courses/stat701/notes/parallel.html
rac<- function(rac_folder, i){
library(RAC)
userpath <- paste0(rac_folder, "site_", i)
setwd(userpath) #working directory
forcings <- Bream_pop_dataloader(userpath) #load environmental variables
output <- Bream_pop_main(userpath, forcings)} #run growth model
library(foreach)
library(doParallel)
#select numbrer of cores
myCluster <- makeCluster(3, type = "PSOCK")
#activate clusters
registerDoParallel(myCluster)
#parallel process
foreach(i = sites) %dopar% rac(rac_folder, i)
forcings
